{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80wasOIL8kya"
   },
   "source": [
    "<a name=\"Load\"></a>\n",
    "## Load Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnYW2dnSVZz6"
   },
   "source": [
    "Download the images from a GCP bucket (this only needs to run if running on colab or first run on local):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import urllib.parse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iUprO14QS54L"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLsn83pVMqDw",
    "outputId": "7e8b2c92-ad90-4d61-d3b8-ae367133718f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of images is: 13891\n"
     ]
    }
   ],
   "source": [
    "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
    "IMAGE_DIR = './data/images'\n",
    "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
    "EXPECTED_IMAGE_COUNT = 13891\n",
    "\n",
    "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
    "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
    "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
    "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
    "  %sx rm \"{TAR_PATH}\"\n",
    "\n",
    "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFo2l5BYegGv"
   },
   "source": [
    "Read in the train, test, and sample submission CSV files as pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i_Q-Bqfn9Dry"
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
    "\n",
    "\n",
    "def read_csv_from_web(file_name):\n",
    "  url = urllib.parse.urljoin(BASE_URL, file_name)\n",
    "  content = requests.get(url).content\n",
    "  return pd.read_csv(io.StringIO(content.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i_Q-Bqfn9Dry"
   },
   "outputs": [],
   "source": [
    "# Read in csv files.\n",
    "train_path = os.path.join(os.path.dirname(IMAGE_DIR), 'train.csv')\n",
    "if os.path.exists(train_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "else:\n",
    "    train = read_csv_from_web('train.csv')\n",
    "    train.to_csv(train_path, index=False)\n",
    "    \n",
    "test_path = os.path.join(os.path.dirname(IMAGE_DIR), 'test.csv')\n",
    "if os.path.exists(test_path):\n",
    "    test = pd.read_csv(test_path)\n",
    "else:\n",
    "    test = read_csv_from_web('test.csv')\n",
    "    test.to_csv(test_path, index=False)\n",
    "  \n",
    "\n",
    "    \n",
    "extra_path = os.path.join(os.path.dirname(IMAGE_DIR), 'extra_images.csv')\n",
    "if os.path.exists(extra_path):\n",
    "    extra = pd.read_csv(extra_path)\n",
    "else:\n",
    "    extra = read_csv_from_web('extra_images.csv')\n",
    "    extra.to_csv(extra_path, index=False)\n",
    "   \n",
    "# Convert image_location strings to lowercase.\n",
    "for df in [train, test]:\n",
    "  df.image_location = df.image_location.apply(lambda x: x.lower())\n",
    "  assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "      <th>turtle_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2RK4WLN8</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_VP2NW7aV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_VVW0QXLX</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_RVATH2HZ</td>\n",
       "      <td>right</td>\n",
       "      <td>t_id_3b65X5Lw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_2GB90GPS</td>\n",
       "      <td>left</td>\n",
       "      <td>t_id_YjXYTCGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_LM6S0B1M</td>\n",
       "      <td>top</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id image_location      turtle_id\n",
       "0  ID_2RK4WLN8            top  t_id_VP2NW7aV\n",
       "1  ID_VVW0QXLX           left  t_id_qZ0iZYsC\n",
       "2  ID_RVATH2HZ          right  t_id_3b65X5Lw\n",
       "3  ID_2GB90GPS           left  t_id_YjXYTCGC\n",
       "4  ID_LM6S0B1M            top  t_id_d6aYXtor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_6NEDKOYZ</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_57QZ4S9N</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_OCGGJS5X</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_R2993S3S</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_2E011NB0</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id image_location\n",
       "0  ID_6NEDKOYZ            top\n",
       "1  ID_57QZ4S9N           left\n",
       "2  ID_OCGGJS5X           left\n",
       "3  ID_R2993S3S            top\n",
       "4  ID_2E011NB0           left"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>turtle_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_Y0KYE5XD</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_8JTIQ4UI</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_LSXPZYSN</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_SHZ2HDSP</td>\n",
       "      <td>t_id_he7JTQxO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_6TOFB06E</td>\n",
       "      <td>t_id_xry0Yg2j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id      turtle_id\n",
       "0  ID_Y0KYE5XD  t_id_he7JTQxO\n",
       "1  ID_8JTIQ4UI  t_id_he7JTQxO\n",
       "2  ID_LSXPZYSN  t_id_he7JTQxO\n",
       "3  ID_SHZ2HDSP  t_id_he7JTQxO\n",
       "4  ID_6TOFB06E  t_id_xry0Yg2j"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lij8pp6xVGBG"
   },
   "source": [
    "## Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bc2qIh1fVq-i"
   },
   "outputs": [],
   "source": [
    "# Dataset to generate triplets (anchor, positive, negative) for training\n",
    "class TripletDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, labels_df, num_triplets, easy_mode=False, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.df = labels_df\n",
    "        self.num_triplets = num_triplets\n",
    "        self.transform = transform\n",
    "        self.training_triplets = self.generate_triplets(self.df, self.num_triplets, easy_mode)\n",
    "        self.easy_mode = easy_mode\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_triplets(df, num_triplets, easy_mode):\n",
    "\n",
    "        def make_dictionary_for_turtle_classes(df, easy_mode):\n",
    "            orientations = df['image_location'].unique().tolist()\n",
    "            turtle_classes = {}\n",
    "            if easy_mode:\n",
    "              for turtle_id in train['turtle_id'].unique():\n",
    "                for orientation in orientations:\n",
    "                  turtle_image_ids = train[(train['turtle_id']==turtle_id) & (train['image_location']==orientation)]['image_id'].tolist()\n",
    "                  turtle_classes[turtle_id]=turtle_image_ids\n",
    "            else:\n",
    "              for turtle_id in train['turtle_id'].unique():\n",
    "                turtle_image_ids = train[train['turtle_id']==turtle_id]['image_id'].tolist()\n",
    "                turtle_classes[turtle_id]=turtle_image_ids\n",
    "            return turtle_classes\n",
    "\n",
    "        triplets = []\n",
    "        classes = df['turtle_id'].unique()\n",
    "        turtle_classes = make_dictionary_for_turtle_classes(df, easy_mode)\n",
    "\n",
    "        for _ in range(num_triplets):\n",
    "\n",
    "            '''\n",
    "              - randomly choose anchor, positive and negative images for triplet loss\n",
    "              - anchor and positive images in pos_class\n",
    "              - negative image in neg_class\n",
    "              - at least, two images needed for anchor and positive images in pos_class\n",
    "              - negative image should have different class as anchor and positive images by definition\n",
    "            '''\n",
    "\n",
    "            pos_class = np.random.choice(classes)\n",
    "            neg_class = np.random.choice(classes)\n",
    "            while len(turtle_classes[pos_class]) < 2:\n",
    "                pos_class = np.random.choice(classes)\n",
    "            while pos_class == neg_class:\n",
    "                neg_class = np.random.choice(classes)\n",
    "\n",
    "\n",
    "            if len(turtle_classes[pos_class]) == 2:\n",
    "                ianc, ipos = np.random.choice(2, size=2, replace=False)\n",
    "            else:\n",
    "                ianc = np.random.randint(0, len(turtle_classes[pos_class]))\n",
    "                ipos = np.random.randint(0, len(turtle_classes[pos_class]))\n",
    "                while ianc == ipos:\n",
    "                    ipos = np.random.randint(0, len(turtle_classes[pos_class]))\n",
    "            ineg = np.random.randint(0, len(turtle_classes[neg_class]))\n",
    "\n",
    "            anc_id = turtle_classes[pos_class][ianc]\n",
    "            pos_id = turtle_classes[pos_class][ipos]\n",
    "            neg_id = turtle_classes[neg_class][ineg]\n",
    "\n",
    "            triplets.append(\n",
    "                [anc_id, pos_id, neg_id, pos_class, neg_class])\n",
    "\n",
    "        return triplets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anc_id, pos_id, neg_id, pos_class, neg_class = self.training_triplets[idx]\n",
    "\n",
    "        anc_img = os.path.join(self.root_dir, anc_id +'.JPG')\n",
    "        pos_img = os.path.join(self.root_dir, pos_id +'.JPG')\n",
    "        neg_img = os.path.join(self.root_dir, neg_id +'.JPG')\n",
    "\n",
    "        anc_img = Image.open(anc_img)\n",
    "        pos_img = Image.open(pos_img)\n",
    "        neg_img = Image.open(neg_img)\n",
    "\n",
    "        # pos_class = torch.from_numpy(np.array([pos_class]).astype('long'))\n",
    "        # neg_class = torch.from_numpy(np.array([neg_class]).astype('long'))\n",
    "\n",
    "        sample = {'anc_img': anc_img, 'pos_img': pos_img, 'neg_img': neg_img, 'pos_class': pos_class,\n",
    "                  'neg_class': neg_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['anc_img'] = self.transform(sample['anc_img'])\n",
    "            sample['pos_img'] = self.transform(sample['pos_img'])\n",
    "            sample['neg_img'] = self.transform(sample['neg_img'])\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.training_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Embedding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bc2qIh1fVq-i"
   },
   "outputs": [],
   "source": [
    "# Dataset to generate samples for embedding loss (img1, img2, +/-1)\n",
    "class EmbeddingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, labels_df, num_samples, easy_mode=False, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.df = labels_df\n",
    "        self.num_samples = num_samples\n",
    "        self.transform = transform\n",
    "        self.training_samples = self.generate_samples(self.df, self.num_triplets, easy_mode)\n",
    "        self.easy_mode = easy_mode\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_samples(df, num_samples, easy_mode):\n",
    "\n",
    "        def make_dictionary_for_turtle_classes(df, classes, easy_mode):\n",
    "            orientations = df['image_location'].unique().tolist()\n",
    "            \n",
    "            turtle_classes = {}\n",
    "            \n",
    "            if easy_mode:\n",
    "                \n",
    "                for turtle_id in classes:\n",
    "                    for orientation in orientations:\n",
    "                        turtle_image_ids = df[(df['turtle_id']==turtle_id) & (df['image_location']==orientation)]['image_id'].tolist()\n",
    "                  \n",
    "            else:\n",
    "                for turtle_id in classes:\n",
    "                    turtle_image_ids = df[df['turtle_id']==df]['image_id'].tolist()\n",
    "                    turtle_classes[turtle_id]=turtle_image_ids\n",
    "            \n",
    "            return turtle_classes\n",
    "\n",
    "        samples = []\n",
    "        classes = df['turtle_id'].unique()\n",
    "        turtle_classes = make_dictionary_for_turtle_classes(df, classes,easy_mode)\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "\n",
    "            \n",
    "            # Randomly select whether to generate positive or negative sample\n",
    "            is_positive_sample = random.choice([True, False])\n",
    "            \n",
    "            if is_positive_sample:\n",
    "                    pos_class = np.random.choice(classes)\n",
    "                    \n",
    "                    if easy_mode:\n",
    "                        orientation = df['image_location'].sample().values[0]\n",
    "                        while len(turtle_classes[pos_class][orientation]) < 2:\n",
    "                            pos_class = np.random.choice(classes)\n",
    "                            orientation = df['image_location'].sample().values[0]\n",
    "                        pos_imgs = turtle_classes[pos_class][orientation]\n",
    "                    else:\n",
    "                        while len(turtle_classes[pos_class]) < 2:\n",
    "                            pos_class = np.random.choice(classes)\n",
    "                        pos_imgs = turtle_classes[pos_class]\n",
    "                    \n",
    "                    img1, img2 = np.random.choice(pos_imgs, size=2, replace=False)\n",
    "                    \n",
    "                    sample = (img1, img2, 1)\n",
    "                    \n",
    "            else:\n",
    "                    pos_class = np.random.choice(classes)\n",
    "                    neg_class = np.random.choice(classes)\n",
    "                    # Resample if positive and negative classes are same\n",
    "                    while pos_class == neg_class:\n",
    "                        neg_class = np.random.choice(classes)\n",
    "                    if easy_mode:\n",
    "                        orientation = df['image_location'].sample().values[0]\n",
    "                        pos_imgs = turtle_classes[pos_class][orientation]\n",
    "                        # Resample if negative class has no images with same orientation\n",
    "                        while len(turtle_classes[neg_class][orientation])==0:\n",
    "                            neg_class = np.random.choice(classes)\n",
    "                        \n",
    "                        neg_imgs = turtle_classes[neg_class][orientation]\n",
    "                    else:\n",
    "                        pos_imgs = turtle_classes[pos_class]\n",
    "                        neg_imgs = turtle_classes[neg_class]\n",
    "                            \n",
    "                    img1 = np.random.choice(pos_imgs)\n",
    "                    img2 = np.random.choice(neg_imgs)\n",
    "                    \n",
    "                    sample = (img1, img2, -1)\n",
    "                    \n",
    "            samples.append(samples)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_id, img2_id, y = self.samples[idx]\n",
    "\n",
    "        img1_path = os.path.join(self.root_dir, img1_id +'.JPG')\n",
    "        img2_path = os.path.join(self.root_dir, img2_id +'.JPG')\n",
    "\n",
    "        img1 = Image.open(img1_path)\n",
    "        img2 = Image.open(img2_path)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Dataset \n",
    "Treats the problem as a simple classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bc2qIh1fVq-i"
   },
   "outputs": [],
   "source": [
    "# Dataset to generate triplets (anchor, positive, negative) for training\n",
    "class TurtleDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root_dir (string): Root directory of dataset  images\n",
    "        labels_df (Dataframe): \n",
    "        label_ids (list): list of ids in training set\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        include_orientation (boolean, optional): whether to include orientation as well\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, labels_df, label_ids, transform=None, include_orientation=True):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.include_orientation = include_orientation\n",
    "        if self.include_orientation:\n",
    "            # self.df = pd.concat([labels_df['image_id'], \n",
    "            #                      pd.get_dummies(labels_df['image_location']), \n",
    "            #                      pd.get_dummies(labels_df['turtle_id'])], \n",
    "            #                     axis=1)\n",
    "            self.df = labels_df\n",
    "        else:\n",
    "            self.df = labels_df[['image_id', 'turtle_id']]\n",
    "        # self.df = pd.concat([labels_df['image_id'], pd.get_dummies(labels_df['image_location']), labels_df['turtle_id']], axis=1)\n",
    "        self.turtle_ids = label_ids\n",
    "        self.transform = transform\n",
    "        self.orientation_map = {'left': 0,\n",
    "                                'right': 1,\n",
    "                                'top': 2}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # id_labels = self.df.loc[idx, self.df.columns.str.startswith('t_id')].values.argmax()\n",
    "        # id_labels = self.df.loc[idx, self.df.columns.str.startswith('t_id')].values\n",
    "        \n",
    "        \n",
    "        turtle_id = self.df.loc[idx, 'turtle_id']\n",
    "        try:\n",
    "            id_label = turtle_ids.index(turtle_id)\n",
    "        except ValueError:\n",
    "            id_label = len(self.turtle_ids)\n",
    "        \n",
    "        image_id = self.df.loc[idx, 'image_id']\n",
    "        img_path = os.path.join(self.root_dir, image_id +'.JPG')\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        \n",
    "        if self.include_orientation:\n",
    "            try:\n",
    "                orientation_label = self.orientation_map[self.df.loc[idx, 'image_location']]\n",
    "            except:\n",
    "                orientation_label = random.choice([0,1,2])\n",
    "\n",
    "            return {'img':img,\n",
    "                    'image_id':image_id,\n",
    "                    'orientation':orientation_label}\n",
    "        else:\n",
    "            \n",
    "            return {'img':img, \n",
    "                    'image_id':image_id,\n",
    "                    'id':id_label}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some unknown turtles to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "turtle_ids = train.turtle_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_ids = set(extra.turtle_id.unique()) - set(train.turtle_id.unique())\n",
    "\n",
    "unknown_train_ids = random.sample(list(unknown_ids), 100)\n",
    "\n",
    "train_df = [train]\n",
    "for unknown_train_id in unknown_train_ids:\n",
    "    train_df.append(extra[extra.turtle_id==unknown_train_id])\n",
    "\n",
    "train_df = pd.concat(train_df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2165"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unknown_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504 images of unkown turtles added\n"
     ]
    }
   ],
   "source": [
    "print(\"%d images of unkown turtles added\"%train_df.image_location.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df.image_location.isna(), 'turtle_id'] = 'new_turtle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "turtle_weights = (train_df.groupby('turtle_id')['image_id'].count()/train_df.shape[0]).reset_index().sort_values('turtle_id', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "turtle_ids = turtle_weights['turtle_id'].tolist()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qahW009DB72E"
   },
   "outputs": [],
   "source": [
    "# A custom transform to pad all images in a batch to same size,  taken from https://discuss.pytorch.org/t/how-to-resize-and-pad-in-a-torchvision-transforms-compose/71850/5\n",
    "class SquarePad:\n",
    "\tdef __call__(self, image):\n",
    "\t\tw, h = image.size\n",
    "\t\tmax_wh = np.max([w, h])\n",
    "\t\thp = int((max_wh - w) / 2)\n",
    "\t\tvp = int((max_wh - h) / 2)\n",
    "\t\tpadding = (hp, vp, hp, vp)\n",
    "\t\treturn F.pad(image, padding, 0, 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YWZ6OIUW1YDn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=5):\n",
    "  \"\"\"Computes the average precision at k.\n",
    "\n",
    "  Args:\n",
    "    actual: The turtle ID to be predicted.\n",
    "    predicted : A list of predicted turtle IDs (order does matter).\n",
    "    k : The maximum number of predicted elements.\n",
    "\n",
    "  Returns:\n",
    "    The average precision at k.\n",
    "  \"\"\"\n",
    "  if len(predicted) > k:\n",
    "    predicted = predicted[:k]\n",
    "\n",
    "  score = 0.0\n",
    "  num_hits = 0.0\n",
    "\n",
    "  for i, p in enumerate(predicted):\n",
    "    if p == actual and p not in predicted[:i]:\n",
    "      num_hits += 1.0\n",
    "      score += num_hits / (i + 1.0)\n",
    "\n",
    "  return score\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "  \"\"\" Computes the mean average precision at k.\n",
    "\n",
    "    The turtle ID at actual[i] will be used to score predicted[i][:k] so order\n",
    "    matters throughout!\n",
    "\n",
    "    actual: A list of the true turtle IDs to score against.\n",
    "    predicted: A list of lists of predicted turtle IDs.\n",
    "    k: The size of the window to score within.\n",
    "\n",
    "    Returns:\n",
    "      The mean average precision at k.\n",
    "  \"\"\"\n",
    "  return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_idx(idx, ids=turtle_ids):\n",
    "    try:\n",
    "        return ids[idx]\n",
    "    except IndexError:\n",
    "        return \"new_turtle\"\n",
    "\n",
    "mapper = np.vectorize(get_id_from_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "JWb22YXTyKIt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-bcdf34b7.pth\" to /home/xion/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-bcdf34b7.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732f578400104a1f90c5758d64789c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36882185.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_conv = torchvision.models.efficientnet_b2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNormActivation(\n",
       "  (0): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): SiLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze all weights\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add a new layer on top\n",
    "num_ftrs = model_conv.classifier[1].in_features\n",
    "model_conv.classifier = nn.Sequential(nn.Dropout(p=0.3, inplace=True), nn.Linear(num_ftrs,len(turtle_ids)+1), nn.ReLU())\n",
    "# model_conv.classifier[6] = nn.Linear(num_ftrs,100)\n",
    "\n",
    "# Unfreeze the weights of the classifier\n",
    "model_conv.requires_grad_(True)\n",
    "\n",
    "# AS well as the last feature layers\n",
    "model_conv.features[-1].requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "qahW009DB72E"
   },
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "                                    SquarePad(),\n",
    "                                    transforms.PILToTensor(),\n",
    "                                    transforms.ConvertImageDtype(torch.float32),\n",
    "                                    transforms.Resize((128,128))\n",
    "                                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "Y0tRzpnKo27I"
   },
   "outputs": [],
   "source": [
    "dataset = TurtleDataSet(IMAGE_DIR, train_df, turtle_ids, transform=img_transform, include_orientation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch_steps = int(np.ceil(len(dataset)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epoch_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy = nn.CrossEntropyLoss(weight=torch.tensor(turtle_weights['image_id'].values, dtype=torch.float).to(device))\n",
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0"
   },
   "outputs": [],
   "source": [
    "model_conv.to(device)\n",
    "model_conv.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_k_precisions = []\n",
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "S2PGm8o7SRXy"
   },
   "outputs": [],
   "source": [
    "optimizer_model = optim.AdamW(filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "                             lr=0.001, weight_decay=0.001)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_model,\n",
    "                                                   max_lr=0.0001,\n",
    "                                                   anneal_strategy='linear',\n",
    "                                                   epochs=50,\n",
    "                                                   steps_per_epoch=num_epoch_steps\n",
    "                                                   # three_phase=True\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - MAP@k : 0.023783 - Learning Rate : 0.000010: 100%|████████████████████████████████████████████████████████| 21/21 [02:20<00:00,  6.71s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - MAP@k : 0.031093 - Loss 4.605620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - MAP@k : 0.105618 - Learning Rate : 0.000017: 100%|████████████████████████████████████████████████████████| 21/21 [01:53<00:00,  5.39s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - MAP@k : 0.073767 - Loss 4.536718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - MAP@k : 0.248689 - Learning Rate : 0.000023: 100%|████████████████████████████████████████████████████████| 21/21 [01:57<00:00,  5.57s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - MAP@k : 0.193409 - Loss 4.374535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - MAP@k : 0.366479 - Learning Rate : 0.000030: 100%|████████████████████████████████████████████████████████| 21/21 [01:54<00:00,  5.47s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - MAP@k : 0.286865 - Loss 4.145791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - MAP@k : 0.408989 - Learning Rate : 0.000036: 100%|████████████████████████████████████████████████████████| 21/21 [01:58<00:00,  5.64s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - MAP@k : 0.384295 - Loss 3.817629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - MAP@k : 0.488951 - Learning Rate : 0.000043: 100%|████████████████████████████████████████████████████████| 21/21 [01:59<00:00,  5.70s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - MAP@k : 0.496039 - Loss 3.441750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - MAP@k : 0.602247 - Learning Rate : 0.000049: 100%|████████████████████████████████████████████████████████| 21/21 [01:58<00:00,  5.63s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - MAP@k : 0.598929 - Loss 3.088528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - MAP@k : 0.672285 - Learning Rate : 0.000055: 100%|████████████████████████████████████████████████████████| 21/21 [02:01<00:00,  5.80s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - MAP@k : 0.680265 - Loss 2.736912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - MAP@k : 0.756367 - Learning Rate : 0.000062: 100%|████████████████████████████████████████████████████████| 21/21 [02:03<00:00,  5.86s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - MAP@k : 0.755834 - Loss 2.373123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - MAP@k : 0.711049 - Learning Rate : 0.000068: 100%|███████████████████████████████████████████████████████| 21/21 [02:05<00:00,  5.98s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - MAP@k : 0.807774 - Loss 2.049667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - MAP@k : 0.859925 - Learning Rate : 0.000075: 100%|███████████████████████████████████████████████████████| 21/21 [01:59<00:00,  5.69s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - MAP@k : 0.842896 - Loss 1.753963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - MAP@k : 0.953184 - Learning Rate : 0.000081: 100%|███████████████████████████████████████████████████████| 21/21 [02:03<00:00,  5.86s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - MAP@k : 0.865795 - Loss 1.494583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - MAP@k : 0.919476 - Learning Rate : 0.000087: 100%|███████████████████████████████████████████████████████| 21/21 [02:02<00:00,  5.83s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - MAP@k : 0.894498 - Loss 1.275036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - MAP@k : 0.919476 - Learning Rate : 0.000094: 100%|███████████████████████████████████████████████████████| 21/21 [02:03<00:00,  5.87s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - MAP@k : 0.922151 - Loss 1.064271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - MAP@k : 0.902622 - Learning Rate : 0.000100: 100%|███████████████████████████████████████████████████████| 21/21 [01:59<00:00,  5.71s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - MAP@k : 0.939293 - Loss 0.888197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - MAP@k : 0.958801 - Learning Rate : 0.000097: 100%|███████████████████████████████████████████████████████| 21/21 [02:04<00:00,  5.93s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - MAP@k : 0.953637 - Loss 0.745621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - MAP@k : 0.950375 - Learning Rate : 0.000094: 100%|███████████████████████████████████████████████████████| 21/21 [02:08<00:00,  6.10s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - MAP@k : 0.963497 - Loss 0.601906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - MAP@k : 0.971910 - Learning Rate : 0.000091: 100%|███████████████████████████████████████████████████████| 21/21 [02:08<00:00,  6.11s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - MAP@k : 0.971976 - Loss 0.504163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - MAP@k : 0.994382 - Learning Rate : 0.000088: 100%|███████████████████████████████████████████████████████| 21/21 [02:01<00:00,  5.80s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - MAP@k : 0.981032 - Loss 0.423900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - MAP@k : 0.986891 - Learning Rate : 0.000086: 100%|███████████████████████████████████████████████████████| 21/21 [02:06<00:00,  6.02s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - MAP@k : 0.988215 - Loss 0.360728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - MAP@k : 0.988764 - Learning Rate : 0.000083: 100%|███████████████████████████████████████████████████████| 21/21 [02:08<00:00,  6.11s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - MAP@k : 0.990474 - Loss 0.301985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - MAP@k : 0.988764 - Learning Rate : 0.000080: 100%|███████████████████████████████████████████████████████| 21/21 [02:04<00:00,  5.95s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - MAP@k : 0.989898 - Loss 0.266454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - MAP@k : 1.000000 - Learning Rate : 0.000077: 100%|███████████████████████████████████████████████████████| 21/21 [02:34<00:00,  7.37s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - MAP@k : 0.993744 - Loss 0.228887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - MAP@k : 0.991573 - Learning Rate : 0.000074: 100%|███████████████████████████████████████████████████████| 21/21 [02:12<00:00,  6.29s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - MAP@k : 0.993398 - Loss 0.213041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - MAP@k : 1.000000 - Learning Rate : 0.000071: 100%|███████████████████████████████████████████████████████| 21/21 [02:03<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - MAP@k : 0.996032 - Loss 0.178607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for sample in pbar:\n",
    "        optimizer_model.zero_grad() \n",
    "        with autocast():\n",
    "            op = model_conv(sample['img'].to(device))\n",
    "            loss = cross_entropy(op, sample['id'].to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_model)\n",
    "        scaler.update()\n",
    "        lr_scheduler.step()\n",
    "        running_loss += loss.item() * sample['img'].size(0)\n",
    "        top_k_precision = mapk(sample['id'], op.topk(5, dim=1).indices)\n",
    "        top_k_precisions.append(top_k_precision)\n",
    "        pbar.set_description('Epoch %d - MAP@k : %f - Learning Rate : %f' % (epoch+1, top_k_precision, lr_scheduler.get_last_lr()[0]))\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print('Epoch %d - MAP@k : %f - Loss %f' % (epoch+1, np.mean(top_k_precisions[-num_epoch_steps:]), epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1d3c5dd30>]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1d3bc1160>]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(top_k_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - MAP@k : 0.916105 - Learning Rate : 0.000068: 100%|████████████████████████████████████████████████████████| 21/21 [01:53<00:00,  5.39s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - MAP@k : 0.915065 - Loss 0.942729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - MAP@k : 0.944757 - Learning Rate : 0.000066: 100%|████████████████████████████████████████████████████████| 21/21 [01:53<00:00,  5.42s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - MAP@k : 0.929432 - Loss 0.867848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - MAP@k : 0.944195 - Learning Rate : 0.000063: 100%|████████████████████████████████████████████████████████| 21/21 [01:52<00:00,  5.35s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - MAP@k : 0.937881 - Loss 0.772991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - MAP@k : 0.944757 - Learning Rate : 0.000060: 100%|████████████████████████████████████████████████████████| 21/21 [01:54<00:00,  5.46s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - MAP@k : 0.943779 - Loss 0.703741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - MAP@k : 0.940075 - Learning Rate : 0.000057: 100%|████████████████████████████████████████████████████████| 21/21 [01:56<00:00,  5.54s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - MAP@k : 0.954035 - Loss 0.640757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - MAP@k : 0.988764 - Learning Rate : 0.000054: 100%|████████████████████████████████████████████████████████| 21/21 [01:54<00:00,  5.45s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - MAP@k : 0.957507 - Loss 0.600407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - MAP@k : 0.958801 - Learning Rate : 0.000051: 100%|████████████████████████████████████████████████████████| 21/21 [01:56<00:00,  5.55s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - MAP@k : 0.968258 - Loss 0.516966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - MAP@k : 0.981273 - Learning Rate : 0.000048: 100%|████████████████████████████████████████████████████████| 21/21 [01:52<00:00,  5.38s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - MAP@k : 0.968702 - Loss 0.497706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - MAP@k : 0.923221 - Learning Rate : 0.000046: 100%|████████████████████████████████████████████████████████| 21/21 [01:59<00:00,  5.70s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - MAP@k : 0.969552 - Loss 0.460454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - MAP@k : 0.983146 - Learning Rate : 0.000043: 100%|███████████████████████████████████████████████████████| 21/21 [01:52<00:00,  5.37s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - MAP@k : 0.975177 - Loss 0.426574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - MAP@k : 0.955056 - Learning Rate : 0.000040: 100%|███████████████████████████████████████████████████████| 21/21 [01:56<00:00,  5.56s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - MAP@k : 0.975731 - Loss 0.391641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - MAP@k : 0.955993 - Learning Rate : 0.000037: 100%|███████████████████████████████████████████████████████| 21/21 [01:53<00:00,  5.38s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - MAP@k : 0.975236 - Loss 0.383967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - MAP@k : 0.988764 - Learning Rate : 0.000034: 100%|███████████████████████████████████████████████████████| 21/21 [01:56<00:00,  5.55s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - MAP@k : 0.980176 - Loss 0.356433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - MAP@k : 0.971910 - Learning Rate : 0.000031: 100%|███████████████████████████████████████████████████████| 21/21 [01:56<00:00,  5.54s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - MAP@k : 0.981140 - Loss 0.332896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - MAP@k : 0.988764 - Learning Rate : 0.000028: 100%|███████████████████████████████████████████████████████| 21/21 [02:56<00:00,  8.39s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - MAP@k : 0.981279 - Loss 0.324188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - MAP@k : 0.960674 - Learning Rate : 0.000026: 100%|███████████████████████████████████████████████████████| 21/21 [02:56<00:00,  8.40s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - MAP@k : 0.983866 - Loss 0.303510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - MAP@k : 0.971910 - Learning Rate : 0.000023: 100%|███████████████████████████████████████████████████████| 21/21 [02:03<00:00,  5.90s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - MAP@k : 0.984383 - Loss 0.292488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - MAP@k : 0.953184 - Learning Rate : 0.000020: 100%|███████████████████████████████████████████████████████| 21/21 [01:57<00:00,  5.62s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - MAP@k : 0.983305 - Loss 0.284562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - MAP@k : 1.000000 - Learning Rate : 0.000017: 100%|███████████████████████████████████████████████████████| 21/21 [01:54<00:00,  5.44s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - MAP@k : 0.987853 - Loss 0.283152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - MAP@k : 0.992509 - Learning Rate : 0.000014: 100%|███████████████████████████████████████████████████████| 21/21 [02:00<00:00,  5.73s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - MAP@k : 0.988080 - Loss 0.259183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 - MAP@k : 0.981273 - Learning Rate : 0.000011: 100%|███████████████████████████████████████████████████████| 21/21 [02:02<00:00,  5.84s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - MAP@k : 0.986490 - Loss 0.261954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 - MAP@k : 0.977528 - Learning Rate : 0.000008: 100%|███████████████████████████████████████████████████████| 21/21 [02:07<00:00,  6.08s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - MAP@k : 0.988141 - Loss 0.257882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 - MAP@k : 0.994382 - Learning Rate : 0.000006: 100%|███████████████████████████████████████████████████████| 21/21 [02:10<00:00,  6.23s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - MAP@k : 0.986631 - Loss 0.254364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 - MAP@k : 0.977528 - Learning Rate : 0.000003: 100%|███████████████████████████████████████████████████████| 21/21 [02:06<00:00,  6.03s/it]\n",
      "  0%|                                                                                                                        | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - MAP@k : 0.986653 - Loss 0.254643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 - MAP@k : 0.988764 - Learning Rate : -0.000000: 100%|██████████████████████████████████████████████████████| 21/21 [01:57<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - MAP@k : 0.988738 - Loss 0.233942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for sample in pbar:\n",
    "        optimizer_model.zero_grad() \n",
    "        with autocast():\n",
    "            op = model_conv(sample['img'].to(device))\n",
    "            loss = cross_entropy(op, sample['id'].to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_model)\n",
    "        scaler.update()\n",
    "        lr_scheduler.step()\n",
    "        running_loss += loss.item() * sample['img'].size(0)\n",
    "        top_k_precision = mapk(sample['id'], op.topk(5, dim=1).indices)\n",
    "        top_k_precisions.append(top_k_precision)\n",
    "        pbar.set_description('Epoch %d - MAP@k : %f - Learning Rate : %f' % (epoch+1, top_k_precision, lr_scheduler.get_last_lr()[0]))\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print('Epoch %d - MAP@k : %f - Loss %f' % (epoch+1, np.mean(top_k_precisions[-num_epoch_steps:]), epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1d3d9a820>]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1d3ced8e0>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(top_k_precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation on extra images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10658, 2)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10154, 2)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra[~extra.turtle_id.isin(unknown_train_ids)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "Y0tRzpnKo27I"
   },
   "outputs": [],
   "source": [
    "extra_dataset = TurtleDataSet(IMAGE_DIR, extra[~extra.turtle_id.isin(unknown_train_ids)].reset_index(),\n",
    "                              turtle_ids, \n",
    "                              transform=img_transform, \n",
    "                              include_orientation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [13:32<00:00, 10.16s/it]\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(extra_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "pbar = tqdm.tqdm(data_loader)\n",
    "model_conv.eval()\n",
    "preds = []\n",
    "image_ids = []\n",
    "val_precisions = []\n",
    "with torch.no_grad():\n",
    "    for sample in pbar:\n",
    "        out = model_conv(sample['img'].to(device))\n",
    "        # break\n",
    "        top_k_precision = mapk(sample['id'], out.topk(5, dim=1).indices)\n",
    "        val_precisions.append(top_k_precision)\n",
    "        pred = out.topk(5, dim=1).indices.cpu().numpy()\n",
    "        preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856975446428573"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved_mem = torch.cuda.memory_reserved(0)\n",
    "allocated_mem = torch.cuda.memory_allocated(0)\n",
    "\n",
    "mem_use = allocated_mem/reserved_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08453042223251431"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['turtle_id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TurtleDataSet(IMAGE_DIR, test, turtle_ids, transform=img_transform, include_orientation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:29<00:00, 29.16s/it]\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=490, shuffle=False, num_workers=1)\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
    "\n",
    "preds = []\n",
    "image_ids = []\n",
    "pbar = tqdm.tqdm(data_loader)\n",
    "model_conv.eval()\n",
    "with torch.no_grad():\n",
    "    for sample in pbar:\n",
    "        image_ids.extend(sample['image_id'])\n",
    "        test_emb = model_conv(sample['img'].to(device))\n",
    "        pred = test_emb.topk(5, dim=1).indices.cpu().numpy()\n",
    "        preds.append(pred)\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([490, 101])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = list(map(lambda x:x.upper(), image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53, 15, 12,  1,  8])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds==100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65, 31, 29, 24, 12])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds==100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mapper(preds)\n",
    "\n",
    "predictions_df = pd.DataFrame({'image_id': image_ids,\n",
    "                               'prediction1': preds[:, 0],\n",
    "                               'prediction2': preds[:, 1],\n",
    "                               'prediction3': preds[:, 2],\n",
    "                               'prediction4': preds[:, 3],\n",
    "                               'prediction5': preds[:, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(os.path.join('predictions', dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M.csv\")),\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As Margin Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for Embedding Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "bc2qIh1fVq-i"
   },
   "outputs": [],
   "source": [
    "# Dataset to generate triplets (anchor, positive, negative) for training\n",
    "class EmbeddingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, labels_df, num_samples, easy_mode=False, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.df = labels_df\n",
    "        self.num_samples = num_samples\n",
    "        self.samples = self.generate_samples(self.df, self.num_samples, easy_mode)\n",
    "        self.easy_mode = easy_mode\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_samples(df, num_samples, easy_mode):\n",
    "\n",
    "        def make_dictionary_for_turtle_classes(df, easy_mode):\n",
    "            \n",
    "            turtle_classes = {}\n",
    "            if easy_mode:\n",
    "                orientations = df['image_location'].unique().tolist()\n",
    "\n",
    "                for turtle_id in df['turtle_id'].unique():\n",
    "                    turtle_classes[turtle_id] = {}\n",
    "                    for orientation in orientations:\n",
    "                      turtle_image_ids = df[(df['turtle_id']==turtle_id) & (df['image_location']==orientation)]['image_id'].tolist()\n",
    "                      turtle_classes[turtle_id][orientation]=turtle_image_ids\n",
    "            else:\n",
    "              for turtle_id in df['turtle_id'].unique():\n",
    "                turtle_image_ids = df[df['turtle_id']==turtle_id]['image_id'].tolist()\n",
    "                turtle_classes[turtle_id]=turtle_image_ids\n",
    "            return turtle_classes\n",
    "\n",
    "        samples = []\n",
    "        classes = df['turtle_id'].unique()\n",
    "        turtle_classes = make_dictionary_for_turtle_classes(df, easy_mode)\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "\n",
    "            '''\n",
    "              - randomly choose anchor, positive and negative images for triplet loss\n",
    "              - anchor and positive images in pos_class\n",
    "              - negative image in neg_class\n",
    "              - at least, two images needed for anchor and positive images in pos_class\n",
    "              - negative image should have different class as anchor and positive images by definition\n",
    "            '''\n",
    "            is_positive_sample = random.choice([True, False])\n",
    "            \n",
    "            # print(turtle_classes)\n",
    "            if is_positive_sample:\n",
    "                pos_class = turtle_classes[np.random.choice(classes)]\n",
    "                if easy_mode:\n",
    "                    # Randomly choose an orientation\n",
    "                    orientations = list(pos_class.keys())\n",
    "                    # We want to train on turtles which have at least been photographed from orientations\n",
    "                    while len(orientations) < 2:\n",
    "                        pos_class = turtle_classes[np.random.choice(classes)]\n",
    "                        orientations = list(pos_class.keys())\n",
    "                    \n",
    "                    orientation = random.choice(orientations)\n",
    "                    while len(pos_class[orientation])<2:\n",
    "                        orientation = random.choice(orientations)\n",
    "                    image_ids = np.random.choice(pos_class[orientation], 2, replace=False)\n",
    "                else:\n",
    "                    # print(pos_class)\n",
    "                    while len(pos_class)<2:\n",
    "                        pos_class = turtle_classes[np.random.choice(classes)]\n",
    "                    image_ids = np.random.choice(pos_class, 2, replace=False)\n",
    "                sample = (image_ids[0], image_ids[1], 1)\n",
    "            else:\n",
    "                pos_class = turtle_classes[np.random.choice(classes)]\n",
    "                neg_class = turtle_classes[np.random.choice(classes)]\n",
    "                \n",
    "                if easy_mode:\n",
    "                    # Randomly choose an orientation\n",
    "                    orientation = random.choice(list(pos_class.keys()))\n",
    "                    pos_id = np.random.choice(pos_class[orientation], 1, replace=False)\n",
    "                    \n",
    "                    # REsample a negative class if the same orientation is not available\n",
    "                    while orientation not in neg_class.keys():\n",
    "                        neg_class = np.random.choice(classes)\n",
    "                        \n",
    "                    neg_id = np.random.choice(neg_class[orientation], 1, replace=False)\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    pos_id = np.random.choice(pos_class, 1, replace=False)\n",
    "                    neg_id = np.random.choice(neg_class, 1, replace=False)\n",
    "                    \n",
    "                sample = (pos_id[0], neg_id[0], -1)\n",
    "            \n",
    "            \n",
    "\n",
    "            samples.append(sample)\n",
    "                \n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id1, id2, y = self.samples[idx]\n",
    "\n",
    "        img1 = os.path.join(self.root_dir, id1 +'.JPG')\n",
    "        img2 = os.path.join(self.root_dir, id2 +'.JPG')\n",
    "\n",
    "        img1 = Image.open(img1)\n",
    "        img2 = Image.open(img2)\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "JWb22YXTyKIt"
   },
   "outputs": [],
   "source": [
    "# Since this model was pretrained above\n",
    "# We want to freeze all weights\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.3, inplace=True)\n",
       "  (1): Linear(in_features=1408, out_features=101, bias=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "id": "JWb22YXTyKIt"
   },
   "outputs": [],
   "source": [
    "# Add a few new layers to replace the old classifier\n",
    "model_conv.classifier = nn.Sequential(nn.Linear(num_ftrs, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU())\n",
    "# model_conv.classifier[6] = nn.Linear(num_ftrs,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for param in model_conv.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Embedding Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_loss = nn.CosineEmbeddingLoss(margin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.to(device)\n",
    "model_conv.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = 4096\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "optimizer_model = optim.SGD(\n",
    "    params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "    lr=0.0001,\n",
    "    momentum=0.0,\n",
    "    dampening=0,\n",
    "    nesterov=False)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer_model, \n",
    "                                                 base_lr=0.00004,\n",
    "                                                 max_lr=0.002, \n",
    "                                                 step_size_up=32, \n",
    "                                                 step_size_down=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "optimizer_model = optim.AdamW(filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "                             lr=0.001, weight_decay=0.001)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_model,\n",
    "                                                   max_lr=0.001,\n",
    "                                                   anneal_strategy='linear',\n",
    "                                                   epochs=20,\n",
    "                                                   steps_per_epoch=int(num_training_samples/batch_size),\n",
    "                                                   three_phase=True\n",
    "                                                   \n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Easy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss : 0.116615 - Learning Rate : 0.000201: 100%|███████████████████████████████████████████████████████████████| 32/32 [06:32<00:00, 12.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss 0.137996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss : 0.088539 - Learning Rate : 0.000362: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:59<00:00, 11.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss 0.093199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss : 0.068488 - Learning Rate : 0.000523: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:38<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss 0.071473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss : 0.053587 - Learning Rate : 0.000683: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:53<00:00, 11.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss 0.061199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss : 0.052847 - Learning Rate : 0.000844: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:51<00:00, 10.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss 0.050993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss : 0.047547 - Learning Rate : 0.000995: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:56<00:00, 11.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss 0.045662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss : 0.032374 - Learning Rate : 0.000834: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:51<00:00, 11.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss 0.037748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss : 0.028742 - Learning Rate : 0.000673: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:55<00:00, 11.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss 0.035424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss : 0.038982 - Learning Rate : 0.000512: 100%|███████████████████████████████████████████████████████████████| 32/32 [05:42<00:00, 10.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss 0.035489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss : 0.025564 - Learning Rate : 0.000352: 100%|██████████████████████████████████████████████████████████████| 32/32 [05:50<00:00, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss 0.029037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    dataset = EmbeddingDataset(IMAGE_DIR, train, num_training_samples, transform=img_transform, easy_mode=True)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for sample in pbar:\n",
    "        img1, img2, y =  sample\n",
    "        optimizer_model.zero_grad() \n",
    "        with autocast():\n",
    "            op1 = model_conv(img1.to(device))\n",
    "            op2 = model_conv(img2.to(device))\n",
    "            loss = cosine_loss(op1, op2, y.to(device))\n",
    "            # loss = cross_entropy(op, sample['id'].to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_model)\n",
    "        scaler.update()\n",
    "        lr_scheduler.step()\n",
    "        running_loss += loss.item() * img1.size(0)\n",
    "        pbar.set_description('Epoch %d - Loss : %f - Learning Rate : %f' % (epoch+1, loss.item(), lr_scheduler.get_last_lr()[0]))\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print('Epoch %d - Loss %f' % (epoch+1, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15380670360755175"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059822056005941704"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1d3b521c0>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected 0.19 - 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Hard training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "optimizer_model = optim.AdamW(filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "                             lr=0.001, weight_decay=0.001)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_model,\n",
    "                                                   max_lr=0.001,\n",
    "                                                   anneal_strategy='linear',\n",
    "                                                   epochs=20,\n",
    "                                                   steps_per_epoch=int(num_training_samples/batch_size),\n",
    "                                                   three_phase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss : 0.197880 - Learning Rate : 0.000202: 100%|███████████████████████████████████████████████████████████████| 16/16 [07:14<00:00, 27.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss 0.214728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss : 0.177340 - Learning Rate : 0.000363: 100%|███████████████████████████████████████████████████████████████| 16/16 [06:59<00:00, 26.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss 0.185545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss : 0.171030 - Learning Rate : 0.000525: 100%|███████████████████████████████████████████████████████████████| 16/16 [06:54<00:00, 25.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss 0.172828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss : 0.163279 - Learning Rate : 0.000687: 100%|███████████████████████████████████████████████████████████████| 16/16 [06:48<00:00, 25.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss 0.167517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss : 0.155634 - Learning Rate : 0.000848: 100%|███████████████████████████████████████████████████████████████| 16/16 [07:04<00:00, 26.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss 0.158635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss : 0.157898 - Learning Rate : 0.000990: 100%|███████████████████████████████████████████████████████████████| 16/16 [06:58<00:00, 26.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss 0.153417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss : 0.142581 - Learning Rate : 0.000828: 100%|███████████████████████████████████████████████████████████████| 16/16 [07:02<00:00, 26.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss 0.148330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss : 0.152484 - Learning Rate : 0.000667: 100%|███████████████████████████████████████████████████████████████| 16/16 [07:23<00:00, 27.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss 0.147837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss : 0.154404 - Learning Rate : 0.000505: 100%|███████████████████████████████████████████████████████████████| 16/16 [07:12<00:00, 27.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss 0.142565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss : 0.143230 - Learning Rate : 0.000343: 100%|██████████████████████████████████████████████████████████████| 16/16 [06:59<00:00, 26.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss 0.142564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Loss : 0.133959 - Learning Rate : 0.000181: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:36<00:00, 28.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Loss 0.140437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Loss : 0.133879 - Learning Rate : 0.000039: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:32<00:00, 28.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Loss 0.141398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Loss : 0.136676 - Learning Rate : 0.000034: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:48<00:00, 29.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Loss 0.139853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Loss : 0.159993 - Learning Rate : 0.000029: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:41<00:00, 28.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Loss 0.142699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Loss : 0.137948 - Learning Rate : 0.000024: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:38<00:00, 28.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Loss 0.142159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Loss : 0.134495 - Learning Rate : 0.000020: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:37<00:00, 28.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Loss 0.138696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Loss : 0.137628 - Learning Rate : 0.000015: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:47<00:00, 29.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Loss 0.137774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Loss : 0.133256 - Learning Rate : 0.000010: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:37<00:00, 28.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Loss 0.133230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Loss : 0.136208 - Learning Rate : 0.000005: 100%|██████████████████████████████████████████████████████████████| 16/16 [07:57<00:00, 29.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Loss 0.137976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Loss : 0.136528 - Learning Rate : -0.000000: 100%|█████████████████████████████████████████████████████████████| 16/16 [07:57<00:00, 29.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Loss 0.138401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    # The dataset is reinitialized on each epoch so that new samples are generated on evry epoch\n",
    "    dataset = EmbeddingDataset(IMAGE_DIR, pd.concat([train, extra]).reset_index(drop=True), num_training_samples,\n",
    "                               transform=img_transform, easy_mode=False)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for sample in pbar:\n",
    "        img1, img2, y =  sample\n",
    "        optimizer_model.zero_grad() \n",
    "        with autocast():\n",
    "            op1 = model_conv(img1.to(device))\n",
    "            op2 = model_conv(img2.to(device))\n",
    "            loss = cosine_loss(op1, op2, y.to(device))\n",
    "            # loss = cross_entropy(op, sample['id'].to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_model)\n",
    "        scaler.update()\n",
    "        lr_scheduler.step()\n",
    "        running_loss += loss.item() * img1.size(0)\n",
    "        pbar.set_description('Epoch %d - Loss : %f - Learning Rate : %f' % (epoch+1, loss.item(), lr_scheduler.get_last_lr()[0]))\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print('Epoch %d - Loss %f' % (epoch+1, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09812385422701482"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected 0.17 - 0.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff1be2d6790>]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Predictions for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = nn.CosineSimilarity(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.concat([train, extra]).reset_index(drop=True)\n",
    "\n",
    "all_train_data = all_train_data.sort_values('turtle_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_dataset = TurtleDataSet(IMAGE_DIR, all_train_data, turtle_ids, transform=img_transform, include_orientation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(indexing_dataset, batch_size=512, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [14:00<00:00, 32.33s/it]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "emb_index = []\n",
    "with torch.no_grad():\n",
    "    for sample in tqdm.tqdm(data_loader):\n",
    "        emb = model_conv(sample['img'].to(device))\n",
    "        emb.to('cpu')\n",
    "        emb_index.append(emb)\n",
    "        ids.append(sample['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = torch.cat(ids)\n",
    "\n",
    "ids = ids.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_index = torch.cat(emb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12803, 64])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['turtle_id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TurtleDataSet(IMAGE_DIR, test, turtle_ids, transform=img_transform, include_orientation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:29<00:00, 29.70s/it]\n"
     ]
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=1)\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
    "\n",
    "test_image_ids = []\n",
    "pbar = tqdm.tqdm(data_loader)\n",
    "model_conv.eval()\n",
    "with torch.no_grad():\n",
    "    for sample in pbar:\n",
    "        test_image_ids.extend(sample['image_id'])\n",
    "        test_emb = model_conv(sample['img'].to(device))\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = []\n",
    "for idx in range(test_emb.shape[0]):\n",
    "    pred = cosine_similarity(emb_index, test_emb[idx]).topk(k=5).indices.cpu().numpy()\n",
    "    pred = list(map(lambda x: ids[x], pred))\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 5)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mapper(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([430, 420, 427, 427, 421])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds=='new_turtle').sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({'image_id': test_image_ids,\n",
    "                               'prediction1': preds[:, 0],\n",
    "                               'prediction2': preds[:, 1],\n",
    "                               'prediction3': preds[:, 2],\n",
    "                               'prediction4': preds[:, 3],\n",
    "                               'prediction5': preds[:, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id         0\n",
       "prediction1    430\n",
       "prediction2     56\n",
       "prediction3     17\n",
       "prediction4      5\n",
       "prediction5      9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions_df=='new_turtle').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(os.path.join('predictions', dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M.csv\")),\n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-03-13-12-19.csv'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('predictions/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_predictions_df = pd.read_csv(os.path.join('predictions', os.listdir('predictions/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, predictions in predictions_df.iterrows():\n",
    "    if sum(predictions=='new_turtle')>1:\n",
    "        replace_pred_idx = predictions.index[predictions=='new_turtle'][1:].tolist()\n",
    "        predictions_df.loc[ix, replace_pred_idx] = class_predictions_df.loc[ix, replace_pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction4    t_id_VP2NW7aV\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "id": "Lot0At3bTfqE"
   },
   "outputs": [],
   "source": [
    "triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=nn.CosineSimilarity(), margin=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "lX7qyeFPVfnj"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaQtb7RdVigm",
    "outputId": "a36a33d6-dbf2-40a5-bb6f-ba1d5adb67c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "id": "Fn6aJs0BbV-3"
   },
   "outputs": [],
   "source": [
    "dataset = TripletDataset(IMAGE_DIR, train, 32768, transform=img_transform, easy_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "id": "Y0tRzpnKo27I"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "S2PGm8o7SRXy"
   },
   "outputs": [],
   "source": [
    "optimizer_model = optim.SGD(\n",
    "            params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "            lr=0.0001,\n",
    "            momentum=0.0,\n",
    "            dampening=0,\n",
    "            nesterov=False\n",
    "        )\n",
    "\n",
    "# optimizer_model = optim.Adam(\n",
    "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "#             lr=0.001,\n",
    "#             betas=(0.9, 0.999),\n",
    "#             eps=1e-08,\n",
    "#             amsgrad=False,\n",
    "#             weight_decay=1e-5\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNi9KT6EtRF9",
    "outputId": "0e34b6db-3887-49f4-cf3c-7ef4bbe778d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_CudaDeviceProperties(name='NVIDIA GeForce RTX 2060', major=7, minor=5, total_memory=6144MB, multi_processor_count=30)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Y0tRzpnKo27I"
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=101, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.to(device)\n",
    "model_conv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss : 0.010000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4096/4096 [36:59<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm.tqdm(data_loader)\n",
    "# with torch.set_grad_enabled(True):\n",
    "for triplet in pbar:\n",
    "    optimizer_model.zero_grad() \n",
    "    with autocast():\n",
    "        anc_embed = model_conv(triplet['anc_img'].to(device))\n",
    "        pos_embed = model_conv(triplet['pos_img'].to(device))\n",
    "        neg_embed = model_conv(triplet['neg_img'].to(device))\n",
    "        loss = triplet_loss(anc_embed, pos_embed, pos_embed)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer_model)\n",
    "    scaler.update()\n",
    "    pbar.set_description('Loss : %f' % loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved_mem = torch.cuda.memory_reserved(0)\n",
    "allocated_mem = torch.cuda.memory_allocated(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1UzR9gq4FGE"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "predictions_from_scratch.to_csv('submission.csv')\n",
    "files.download('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29,  32,  21,   1,  43],\n",
       "       [ 54,  22,   3,  83,  14],\n",
       "       [ 15,   3,  63,  54,  65],\n",
       "       [ 71,  52,  84,  42,  27],\n",
       "       [ 13,  31,   3,  38,  25],\n",
       "       [ 59,  49,  33,  43,  90],\n",
       "       [  2,  30,  43,  76,   7],\n",
       "       [ 31, 100,  46,  16,  93]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['t_id_15bo4NKD', 't_id_Kc1tXDbJ', 't_id_DPYQnZyv',\n",
       "        't_id_qZ0iZYsC', 't_id_8b8sprYe'],\n",
       "       ['t_id_uJXT7dGu', 't_id_ROFhVsy2', 't_id_YjXYTCGC',\n",
       "        't_id_GOIvCduN', 't_id_NW7wn8TC'],\n",
       "       ['t_id_JI6ba2Yx', 't_id_YjXYTCGC', 't_id_D0gA44av',\n",
       "        't_id_uJXT7dGu', 't_id_MwnEYfqe'],\n",
       "       ['t_id_fxTQ5vHC', 't_id_72SiiZCp', 't_id_pCO59rOk',\n",
       "        't_id_bYageLYA', 't_id_mpuNp8mf'],\n",
       "       ['t_id_Ts5LyVQz', 't_id_Kf73l69A', 't_id_YjXYTCGC',\n",
       "        't_id_tjWepji1', 't_id_AOWArhGb'],\n",
       "       ['t_id_WDCMGvI4', 't_id_B7LaSiac', 't_id_2Yn71r7R',\n",
       "        't_id_8b8sprYe', 't_id_2E8o5Jtl'],\n",
       "       ['t_id_3b65X5Lw', 't_id_QqeoI5F3', 't_id_8b8sprYe',\n",
       "        't_id_VFb44eFm', 't_id_utw0thCe'],\n",
       "       ['t_id_Kf73l69A', 'new_turtle', 't_id_smNwfXAT', 't_id_ifWwxWF4',\n",
       "        't_id_Lhp87PBX']], dtype='<U13')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper(out.topk(5, dim=1).indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = read_csv_from_web('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prediction1</th>\n",
       "      <th>prediction2</th>\n",
       "      <th>prediction3</th>\n",
       "      <th>prediction4</th>\n",
       "      <th>prediction5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_6NEDKOYZ</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_57QZ4S9N</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_OCGGJS5X</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_R2993S3S</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_2E011NB0</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "      <td>t_id_qZ0iZYsC</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_d6aYXtor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id prediction1    prediction2    prediction3 prediction4  \\\n",
       "0  ID_6NEDKOYZ  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
       "1  ID_57QZ4S9N  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
       "2  ID_OCGGJS5X  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
       "3  ID_R2993S3S  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
       "4  ID_2E011NB0  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
       "\n",
       "     prediction5  \n",
       "0  t_id_d6aYXtor  \n",
       "1  t_id_d6aYXtor  \n",
       "2  t_id_d6aYXtor  \n",
       "3  t_id_d6aYXtor  \n",
       "4  t_id_d6aYXtor  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 128, 128])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26,  8, 76, 60, 66, 66, 55, 34])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14583333333333331"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(sample['id'], out.topk(5, dim=1).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapk(out,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRXRDtflz2xP"
   },
   "outputs": [],
   "source": [
    "predictions = predictions_from_scratch[[\n",
    "    \"prediction1\", \"prediction2\", \"prediction3\", \"prediction4\", \"prediction5\"\n",
    "]]\n",
    "y_predict = predictions.values.tolist()\n",
    "\n",
    "# We don't actually know the true labels for the test set, so for the purposes\n",
    "# of demonstration we just assume that all of the images in the test set are of\n",
    "# a single turtle:\n",
    "assumed_y = [\"t_id_d6aYXtor\"] * len(y_predict)\n",
    "\n",
    "mapk_result = mapk(assumed_y, y_predict, k=5)\n",
    "print(\"With made up test set labels, our mapk with k=5 is\", mapk_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TurtleNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_orientations, embedding_size):\n",
    "        super(TurtleNet, self).__init__()\n",
    "        \n",
    "        basenet = torchvision.models.alexnet(pretrained=True)\n",
    "        \n",
    "        self.features = basenet.features\n",
    "        # Freeze the conv weights of the pretrained model\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.adpool = nn.AdaptiveAvgPool2d(output_size=(6, 6))\n",
    "        self.dense_layers0 = basenet.classifier\n",
    "        self.dense_layers0[6] = nn.Linear(in_features=4096, out_features=128, bias=True)\n",
    "        \n",
    "        # self.dense_layers1 = nn.Sequential(nn.ReLU(), nn.Linear(in_features=1024, out_features=256, bias=True), nn.ReLU())\n",
    "        # self.dense_layers2 = nn.Sequential(nn.Linear(in_features=512, out_features=256, bias=True), nn.ReLU())\n",
    "        \n",
    "        self.embedding_head = nn.Sequential(nn.Linear(in_features=128, out_features=embedding_size, bias=True), nn.ReLU())\n",
    "        self.classification_head = nn.Sequential(nn.Linear(in_features=128, out_features=num_classes, bias=True), nn.ReLU())\n",
    "        self.orientation_head = nn.Sequential(nn.Linear(in_features=128, out_features=num_orientations, bias=True), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adpool(x)\n",
    "        x = self.dense_layers0(x)\n",
    "        x = self.dense_layers1(x)\n",
    "        \n",
    "        y_aux = self.orientation_head(x)\n",
    "        y_main = self.classification_head(x)\n",
    "        y_emb = self.embedding_head(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return y_main, y_aux, y_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TurtleNet(num_classes=len(turtle_ids)+1, # +1 for the new turtle class\n",
    "                  num_orientations=3, \n",
    "                  embedding_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "S2PGm8o7SRXy"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "            params=filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=0.0001,\n",
    "            momentum=0.0,\n",
    "            dampening=0,\n",
    "            nesterov=False\n",
    "        )\n",
    "\n",
    "# optimizer_model = optim.Adam(\n",
    "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "#             lr=0.001,\n",
    "#             betas=(0.9, 0.999),\n",
    "#             eps=1e-08,\n",
    "#             amsgrad=False,\n",
    "#             weight_decay=1e-5\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qahW009DB72E"
   },
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "                                    SquarePad(),\n",
    "                                    transforms.PILToTensor(),\n",
    "                                    transforms.ConvertImageDtype(torch.float32),\n",
    "                                    transforms.Resize((128,128))\n",
    "                                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Y0tRzpnKo27I"
   },
   "outputs": [],
   "source": [
    "dataset = TurtleDataSet(IMAGE_DIR, train_df, turtle_ids, transform=img_transform, include_orientation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TurtleNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_layers0): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  )\n",
       "  (embedding_head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=101, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (orientation_head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
    "                                                 base_lr=0.00001, \n",
    "                                                 max_lr=0.001, \n",
    "                                                 step_size_up=21, \n",
    "                                                 step_size_down=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_k_precisions = []\n",
    "epoch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 73,  15,   8,  38,  48,  81,  72,  47,  75,  61,  56, 100,  65,  39,\n",
       "          4,  81])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TurtleNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (adpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (dense_layers0): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  )\n",
       "  (embedding_head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=101, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (orientation_head): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (24576x6 and 9216x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mTurtleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madpool(x)\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_layers0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_layers1(x)\n\u001b[1;32m     28\u001b[0m y_aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morientation_head(x)\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (24576x6 and 9216x4096)"
     ]
    }
   ],
   "source": [
    "model(sample['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                      | 0/164 [00:00<?, ?it/s]/home/xion/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  0%|                                                                                                                                                                                      | 0/164 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to GEMM_EX  parameter number 12 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m---> 11\u001b[0m     op_main, op_aux, op_embed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m cross_entropy(op, sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     13\u001b[0m     loss2 \u001b[38;5;241m=\u001b[39m cross_entropy(op, sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mTurtleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[0;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_layers0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_layers1(x)\n\u001b[1;32m     28\u001b[0m     y_aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morientation_head(x)\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, num_workers=1)\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for sample in pbar:\n",
    "        optimizer.zero_grad() \n",
    "        with autocast():\n",
    "            op_main, op_aux, op_embed = model(sample['img'].to(device))\n",
    "            loss1 = cross_entropy(op, sample['id'].to(device))\n",
    "            loss2 = cross_entropy(op, sample['orientation'].to(device))\n",
    "            loss = loss1+0.4*loss2\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_model)\n",
    "        scaler.update()\n",
    "        lr_scheduler.step()\n",
    "        running_loss += loss1.item() * sample['img'].size(0)\n",
    "        top_k_precision = mapk(sample['id'], op_main.topk(5, dim=1).indices)\n",
    "        top_k_precisions.append(top_k_precision)\n",
    "        pbar.set_description('Epoch %d - MAP@k : %f - Learning Rate : %f' % (epoch+1, top_k_precision, lr_scheduler.get_last_lr()[0]))\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    print('Epoch %d - MAP@k : %f - Loss %f' % (epoch+1, np.mean(top_k_precisions[-21:]), epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Model\n",
    "Trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TurtleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TurtleNet, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1,64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        self.feature_classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=32768, out_features=4096, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=4096, out_features=512, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5, inplace=False),\n",
    "            nn.Linear(in_features=512, out_features=100, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.feature_classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = TurtleNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "qahW009DB72E"
   },
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "                                    transforms.Grayscale(num_output_channels=1),\n",
    "                                    SquarePad(),\n",
    "                                    transforms.PILToTensor(),\n",
    "                                    transforms.ConvertImageDtype(torch.float32),\n",
    "                                    transforms.Resize((128,128))\n",
    "                                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out anymemory if possible\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=101, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.to(device)\n",
    "model_conv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Y0tRzpnKo27I"
   },
   "outputs": [],
   "source": [
    "dataset = TurtleDataSet(IMAGE_DIR, train, transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "S2PGm8o7SRXy"
   },
   "outputs": [],
   "source": [
    "optimizer_model = optim.SGD(\n",
    "            params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "            lr=0.0001,\n",
    "            momentum=0.0,\n",
    "            dampening=0,\n",
    "            nesterov=False\n",
    "        )\n",
    "\n",
    "# optimizer_model = optim.Adam(\n",
    "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
    "#             lr=0.001,\n",
    "#             betas=(0.9, 0.999),\n",
    "#             eps=1e-08,\n",
    "#             amsgrad=False,\n",
    "#             weight_decay=1e-5\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sw2hA1aQCQx3",
    "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss : 4.601562: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [01:31<00:00,  2.95it/s]\n",
      "Epoch 2 - Loss : 4.585938: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:43<00:00,  6.23it/s]\n",
      "Epoch 3 - Loss : 4.609375: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:43<00:00,  6.14it/s]\n",
      "Epoch 4 - Loss : 4.570312: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:49<00:00,  5.47it/s]\n",
      "Epoch 5 - Loss : 4.585938: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:47<00:00,  5.71it/s]\n",
      "Epoch 6 - Loss : 4.636719: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:49<00:00,  5.42it/s]\n",
      "Epoch 7 - Loss : 4.570312: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:49<00:00,  5.45it/s]\n",
      "Epoch 8 - Loss : 4.613281: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:48<00:00,  5.55it/s]\n",
      "Epoch 9 - Loss : 4.617188: 100%|████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:48<00:00,  5.54it/s]\n",
      "Epoch 10 - Loss : 4.625000: 100%|███████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:48<00:00,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with torch.set_grad_enabled(True):\n",
    "for epoch in range(10):\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=1)\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    for sample in pbar:\n",
    "        # break\n",
    "        optimizer_model.zero_grad() \n",
    "        with autocast():\n",
    "            op = model_conv(sample['img'].to(device))\n",
    "            loss = cross_entropy(op, sample['id'].to(device))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_model)\n",
    "        scaler.update()\n",
    "        pbar.set_description('Epoch %d - Loss : %f' % (epoch+1, loss.item()))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Turtle_Recall.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
