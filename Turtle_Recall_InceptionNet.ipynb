{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80wasOIL8kya"
      },
      "source": [
        "<a name=\"Load\"></a>\n",
        "## Load Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnYW2dnSVZz6"
      },
      "source": [
        "Download the images from a GCP bucket (this only needs to run if running on colab or first run on local):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cDezGBgS63za"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import urllib.parse\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9N8cD6TRKPix"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "import torch\n",
        "# from skimage import io\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iUprO14QS54L"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OSu2bizX63zc"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLsn83pVMqDw",
        "outputId": "1b67bdf9-2ed4-4150-a81c-6c730da25c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of images is: 13891\n"
          ]
        }
      ],
      "source": [
        "SOURCE_URL = 'https://storage.googleapis.com/dm-turtle-recall/images.tar'\n",
        "IMAGE_DIR = './data/images'\n",
        "TAR_PATH = os.path.join(IMAGE_DIR, os.path.basename(SOURCE_URL))\n",
        "EXPECTED_IMAGE_COUNT = 13891\n",
        "\n",
        "%sx mkdir --parents \"{IMAGE_DIR}\"\n",
        "if len(os.listdir(IMAGE_DIR)) != EXPECTED_IMAGE_COUNT:\n",
        "  %sx wget --no-check-certificate -O \"{TAR_PATH}\" \"{SOURCE_URL}\"\n",
        "  %sx tar --extract --file=\"{TAR_PATH}\" --directory=\"{IMAGE_DIR}\"\n",
        "  %sx rm \"{TAR_PATH}\"\n",
        "\n",
        "print(f'The total number of images is: {len(os.listdir(IMAGE_DIR))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFo2l5BYegGv"
      },
      "source": [
        "Read in the train, test, and sample submission CSV files as pandas dataframes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i_Q-Bqfn9Dry"
      },
      "outputs": [],
      "source": [
        "BASE_URL = 'https://storage.googleapis.com/dm-turtle-recall/'\n",
        "\n",
        "\n",
        "def read_csv_from_web(file_name):\n",
        "  url = urllib.parse.urljoin(BASE_URL, file_name)\n",
        "  content = requests.get(url).content\n",
        "  return pd.read_csv(io.StringIO(content.decode('utf-8')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s6_oVJe863zf"
      },
      "outputs": [],
      "source": [
        "# Read in csv files.\n",
        "train_path = os.path.join(os.path.dirname(IMAGE_DIR), 'train.csv')\n",
        "if os.path.exists(train_path):\n",
        "    train = pd.read_csv(train_path)\n",
        "else:\n",
        "    train = read_csv_from_web('train.csv')\n",
        "    train.to_csv(train_path, index=False)\n",
        "    \n",
        "test_path = os.path.join(os.path.dirname(IMAGE_DIR), 'test.csv')\n",
        "if os.path.exists(test_path):\n",
        "    test = pd.read_csv(test_path)\n",
        "else:\n",
        "    test = read_csv_from_web('test.csv')\n",
        "    test.to_csv(test_path, index=False)\n",
        "  \n",
        "\n",
        "    \n",
        "extra_path = os.path.join(os.path.dirname(IMAGE_DIR), 'extra_images.csv')\n",
        "if os.path.exists(extra_path):\n",
        "    extra = pd.read_csv(extra_path)\n",
        "else:\n",
        "    extra = read_csv_from_web('extra_images.csv')\n",
        "    extra.to_csv(extra_path, index=False)\n",
        "   \n",
        "# Convert image_location strings to lowercase.\n",
        "for df in [train, test]:\n",
        "  df.image_location = df.image_location.apply(lambda x: x.lower())\n",
        "  assert set(df.image_location.unique()) == set(['left', 'right', 'top'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4Z5aoOz63zf"
      },
      "source": [
        "Quickly check the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w2Ssn-og63zg",
        "outputId": "dc1b1f6a-4ad5-40cd-84ec-a34259cedd79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      image_id image_location      turtle_id\n",
              "0  ID_2RK4WLN8            top  t_id_VP2NW7aV\n",
              "1  ID_VVW0QXLX           left  t_id_qZ0iZYsC\n",
              "2  ID_RVATH2HZ          right  t_id_3b65X5Lw\n",
              "3  ID_2GB90GPS           left  t_id_YjXYTCGC\n",
              "4  ID_LM6S0B1M            top  t_id_d6aYXtor"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b0094e5-5928-42e6-aff8-2f4786613a0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>image_location</th>\n",
              "      <th>turtle_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_2RK4WLN8</td>\n",
              "      <td>top</td>\n",
              "      <td>t_id_VP2NW7aV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_VVW0QXLX</td>\n",
              "      <td>left</td>\n",
              "      <td>t_id_qZ0iZYsC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_RVATH2HZ</td>\n",
              "      <td>right</td>\n",
              "      <td>t_id_3b65X5Lw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_2GB90GPS</td>\n",
              "      <td>left</td>\n",
              "      <td>t_id_YjXYTCGC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_LM6S0B1M</td>\n",
              "      <td>top</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b0094e5-5928-42e6-aff8-2f4786613a0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b0094e5-5928-42e6-aff8-2f4786613a0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b0094e5-5928-42e6-aff8-2f4786613a0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gpJb9Hgn63zg",
        "outputId": "e4fab5d7-4628-45d0-813c-b8ee6d22ee06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      image_id image_location\n",
              "0  ID_6NEDKOYZ            top\n",
              "1  ID_57QZ4S9N           left\n",
              "2  ID_OCGGJS5X           left\n",
              "3  ID_R2993S3S            top\n",
              "4  ID_2E011NB0           left"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edd0d962-2e0a-4ec8-9087-86ab17e2e821\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>image_location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_6NEDKOYZ</td>\n",
              "      <td>top</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_57QZ4S9N</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_OCGGJS5X</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_R2993S3S</td>\n",
              "      <td>top</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_2E011NB0</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edd0d962-2e0a-4ec8-9087-86ab17e2e821')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-edd0d962-2e0a-4ec8-9087-86ab17e2e821 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-edd0d962-2e0a-4ec8-9087-86ab17e2e821');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GrdGDgan63zh",
        "outputId": "84eaf8d5-7a36-4e1e-c63f-a40bbb0123ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      image_id      turtle_id\n",
              "0  ID_Y0KYE5XD  t_id_he7JTQxO\n",
              "1  ID_8JTIQ4UI  t_id_he7JTQxO\n",
              "2  ID_LSXPZYSN  t_id_he7JTQxO\n",
              "3  ID_SHZ2HDSP  t_id_he7JTQxO\n",
              "4  ID_6TOFB06E  t_id_xry0Yg2j"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f340d748-e0ba-4885-b7bb-4587d268ce4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>turtle_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_Y0KYE5XD</td>\n",
              "      <td>t_id_he7JTQxO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_8JTIQ4UI</td>\n",
              "      <td>t_id_he7JTQxO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_LSXPZYSN</td>\n",
              "      <td>t_id_he7JTQxO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_SHZ2HDSP</td>\n",
              "      <td>t_id_he7JTQxO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_6TOFB06E</td>\n",
              "      <td>t_id_xry0Yg2j</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f340d748-e0ba-4885-b7bb-4587d268ce4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f340d748-e0ba-4885-b7bb-4587d268ce4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f340d748-e0ba-4885-b7bb-4587d268ce4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "extra.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfU5dBdg63zn"
      },
      "source": [
        "### Simple Dataset \n",
        "Treats the problem as a simple classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DTGJMGpb63zn"
      },
      "outputs": [],
      "source": [
        "# Dataset to generate triplets (anchor, positive, negative) for training\n",
        "class TurtleDataSet(Dataset):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        root_dir (string): Root directory of dataset  images\n",
        "        labels_df (Dataframe): \n",
        "        label_ids (list): list of ids in training set\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "        include_orientation (boolean, optional): whether to include orientation as well\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir, labels_df, label_ids, transform=None, include_orientation=True):\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.include_orientation = include_orientation\n",
        "        if self.include_orientation:\n",
        "            # self.df = pd.concat([labels_df['image_id'], \n",
        "            #                      pd.get_dummies(labels_df['image_location']), \n",
        "            #                      pd.get_dummies(labels_df['turtle_id'])], \n",
        "            #                     axis=1)\n",
        "            self.df = labels_df\n",
        "        else:\n",
        "            self.df = labels_df[['image_id', 'turtle_id']]\n",
        "        # self.df = pd.concat([labels_df['image_id'], pd.get_dummies(labels_df['image_location']), labels_df['turtle_id']], axis=1)\n",
        "        self.turtle_ids = label_ids\n",
        "        self.transform = transform\n",
        "        self.orientation_map = {'left': 0,\n",
        "                                'right': 1,\n",
        "                                'top': 2}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        \n",
        "        turtle_id = self.df.loc[idx, 'turtle_id']\n",
        "        try:\n",
        "            id_label = turtle_ids.index(turtle_id)\n",
        "        except ValueError:\n",
        "            id_label = len(self.turtle_ids)\n",
        "        \n",
        "        image_id = self.df.loc[idx, 'image_id']\n",
        "        img_path = os.path.join(self.root_dir, image_id +'.JPG')\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            \n",
        "        \n",
        "        if self.include_orientation:\n",
        "            try:\n",
        "                orientation_label = self.orientation_map[self.df.loc[idx, 'image_location']]\n",
        "            except:\n",
        "                orientation_label = random.choice([0,1,2])\n",
        "\n",
        "            return {'img':img,\n",
        "                    'image_id':image_id,\n",
        "                    'id':id_label,\n",
        "                    'orientation':orientation_label}\n",
        "        else:\n",
        "            \n",
        "            return {'img':img, \n",
        "                    'image_id':image_id,\n",
        "                    'id':id_label}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L739lAJn63zo"
      },
      "source": [
        "Add some unknown turtles to the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yPIuwcIy63zo"
      },
      "outputs": [],
      "source": [
        "turtle_ids = train.turtle_id.unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OnvJTHBY63zo"
      },
      "outputs": [],
      "source": [
        "unknown_ids = set(extra.turtle_id.unique()) - set(train.turtle_id.unique())\n",
        "\n",
        "unknown_train_ids = random.sample(list(unknown_ids), 100)\n",
        "\n",
        "train_df = [train]\n",
        "for unknown_train_id in unknown_train_ids:\n",
        "    train_df.append(extra[extra.turtle_id==unknown_train_id])\n",
        "\n",
        "train_df = pd.concat(train_df).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy0NpFDP63zo",
        "outputId": "d5b9ca99-9f9c-4ef7-c3e4-dacc5338e92f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2145"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8tjTbQc63zp",
        "outputId": "613a6512-0570-4d52-c474-ee3a48e339d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2165"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(unknown_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyBaT2Ao63zp",
        "outputId": "7953574d-baa8-4b37-9370-26e8e63a3685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "435 images of unkown turtles added\n"
          ]
        }
      ],
      "source": [
        "print(\"%d images of unkown turtles added\"%train_df.image_location.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "n886tqgK63zp"
      },
      "outputs": [],
      "source": [
        "train_df.loc[train_df.image_location.isna(), 'turtle_id'] = 'new_turtle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "th7j_Jv263zp"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.drop('index', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JMZw4hYB63zq"
      },
      "outputs": [],
      "source": [
        "turtle_weights = (train_df.groupby('turtle_id')['image_id'].count()/train_df.shape[0]).reset_index().sort_values('turtle_id', ascending=False).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rG5nR2mg63zq"
      },
      "outputs": [],
      "source": [
        "turtle_ids = turtle_weights['turtle_id'].tolist()[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8u8vCxOe63zq"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY8SV23Q63zq"
      },
      "source": [
        "## Image Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "qahW009DB72E"
      },
      "outputs": [],
      "source": [
        "# A custom transform to pad all images in a batch to same size,  taken from https://discuss.pytorch.org/t/how-to-resize-and-pad-in-a-torchvision-transforms-compose/71850/5\n",
        "class SquarePad:\n",
        "\tdef __call__(self, image):\n",
        "\t\tw, h = image.size\n",
        "\t\tmax_wh = np.max([w, h])\n",
        "\t\thp = int((max_wh - w) / 2)\n",
        "\t\tvp = int((max_wh - h) / 2)\n",
        "\t\tpadding = (hp, vp, hp, vp)\n",
        "\t\treturn F.pad(image, padding, 0, 'constant')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDYSJHKC63zq"
      },
      "source": [
        "## Competition Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YWZ6OIUW1YDn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def apk(actual, predicted, k=5):\n",
        "  \"\"\"Computes the average precision at k.\n",
        "\n",
        "  Args:\n",
        "    actual: The turtle ID to be predicted.\n",
        "    predicted : A list of predicted turtle IDs (order does matter).\n",
        "    k : The maximum number of predicted elements.\n",
        "\n",
        "  Returns:\n",
        "    The average precision at k.\n",
        "  \"\"\"\n",
        "  if len(predicted) > k:\n",
        "    predicted = predicted[:k]\n",
        "\n",
        "  score = 0.0\n",
        "  num_hits = 0.0\n",
        "\n",
        "  for i, p in enumerate(predicted):\n",
        "    if p == actual and p not in predicted[:i]:\n",
        "      num_hits += 1.0\n",
        "      score += num_hits / (i + 1.0)\n",
        "\n",
        "  return score\n",
        "\n",
        "\n",
        "def mapk(actual, predicted, k=5):\n",
        "  \"\"\" Computes the mean average precision at k.\n",
        "\n",
        "    The turtle ID at actual[i] will be used to score predicted[i][:k] so order\n",
        "    matters throughout!\n",
        "\n",
        "    actual: A list of the true turtle IDs to score against.\n",
        "    predicted: A list of lists of predicted turtle IDs.\n",
        "    k: The size of the window to score within.\n",
        "\n",
        "    Returns:\n",
        "      The mean average precision at k.\n",
        "  \"\"\"\n",
        "  return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29vlnp9563zr"
      },
      "outputs": [],
      "source": [
        "def get_id_from_idx(idx, ids=turtle_ids):\n",
        "    try:\n",
        "        return ids[idx]\n",
        "    except IndexError:\n",
        "        return \"new_turtle\"\n",
        "\n",
        "mapper = np.vectorize(get_id_from_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD0NfiUP63zr"
      },
      "source": [
        "## As Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNACZlPU63zr"
      },
      "source": [
        "### Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JWb22YXTyKIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "03b3c1ff6fd74aa8841c0d497fa62f8d",
            "c7a76b3b959040329297dc86ccc7a2f5",
            "118596bb302d4ff29aca97565198bdd7",
            "69b0cee3ee7347c0a17932e70ac739bc",
            "7676578519494d28940a7538d39bfa87",
            "b2a46034480b4df4a9d9e37c63f4c999",
            "4f7bcfb271294b529e03d201f92b98e9",
            "2dbbeeb6fd1c42308809d9f5fff5adbf",
            "62d0f34df8b844e3897d66a8ed36d401",
            "65b0e6276294402a9f4a9dd48ca1bfa0",
            "e44a3a6d809d41dfbee8dc5cc53db6e2"
          ]
        },
        "outputId": "9242d4a0-948a-465b-eb99-2139a1d6418d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/104M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03b3c1ff6fd74aa8841c0d497fa62f8d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_conv = torchvision.models.inception_v3(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "agz3sr4vqnjw",
        "outputId": "25f586d4-37ef-4d11-c6ad-7dc3173a199f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-eeda3a56fe66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_conv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, child in model_conv.named_children():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkqd9MuEqHsx",
        "outputId": "ac2d7ea2-8ed8-4d41-ad8d-81b56563eb82"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d_1a_3x3\n",
            "Conv2d_2a_3x3\n",
            "Conv2d_2b_3x3\n",
            "maxpool1\n",
            "Conv2d_3b_1x1\n",
            "Conv2d_4a_3x3\n",
            "maxpool2\n",
            "Mixed_5b\n",
            "Mixed_5c\n",
            "Mixed_5d\n",
            "Mixed_6a\n",
            "Mixed_6b\n",
            "Mixed_6c\n",
            "Mixed_6d\n",
            "Mixed_6e\n",
            "AuxLogits\n",
            "Mixed_7a\n",
            "Mixed_7b\n",
            "Mixed_7c\n",
            "avgpool\n",
            "dropout\n",
            "fc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all weights\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Add new layer for auxilary task\n",
        "aux_in_features = model_conv.AuxLogits.fc.in_features\n",
        "model_conv.AuxLogits.fc = nn.Sequential(nn.Linear(aux_in_features, 3), nn.ReLU())\n",
        "\n",
        "# Add a new layer on top\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "\n",
        "model_conv.fc = nn.Sequential(nn.Linear(num_ftrs,len(turtle_ids)+1), nn.ReLU())\n",
        "\n",
        "# Unfreeze the weights of the classifier\n",
        "for name, child in model_conv.named_children():\n",
        "  # print(name)\n",
        "  if name in ['AuxLogits', 'Mixed_7c',  'Mixed_7b', 'Mixed_7a', 'fc']:\n",
        "    child.requires_grad_(True)\n"
      ],
      "metadata": {
        "id": "zTDMw_cv91CJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oRKTFwBs63zs"
      },
      "outputs": [],
      "source": [
        "img_transform = transforms.Compose([\n",
        "                                    SquarePad(),\n",
        "                                    transforms.PILToTensor(),\n",
        "                                    transforms.ConvertImageDtype(torch.float32),\n",
        "                                    transforms.Resize(( 299, 299)),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "                                                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Y0tRzpnKo27I"
      },
      "outputs": [],
      "source": [
        "dataset = TurtleDataSet(IMAGE_DIR, train_df, turtle_ids, transform=img_transform, include_orientation=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512"
      ],
      "metadata": {
        "id": "H0qnsLADpsN9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch_steps = int(np.ceil(len(dataset)/batch_size))"
      ],
      "metadata": {
        "id": "8QlGBq8Kp4bU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch_steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6eT-Nzop8hT",
        "outputId": "7ca84cbf-b6dd-4912-b733-65816bebed76"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2PGm8o7SRXy"
      },
      "outputs": [],
      "source": [
        "# optimizer_model = optim.SGD(\n",
        "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "#             lr=0.0001,\n",
        "#             momentum=0.0,\n",
        "#             dampening=0,\n",
        "#             nesterov=False\n",
        "#         )\n",
        "\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer_model, \n",
        "#                                                  base_lr=0.00001, \n",
        "#                                                  max_lr=0.001, \n",
        "#                                                  step_size_up=5, \n",
        "#                                                  step_size_down=10)\n",
        "\n",
        "optimizer_model = optim.AdamW(filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "                             lr=0.001, weight_decay=0.001)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_model,\n",
        "                                                   max_lr=0.001,\n",
        "                                                   anneal_strategy='linear',\n",
        "                                                   epochs=30,\n",
        "                                                   steps_per_epoch=num_epoch_steps,\n",
        "                                                   three_phase=True\n",
        "                                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AxlauhC63zs"
      },
      "outputs": [],
      "source": [
        "# cross_entropy = nn.CrossEntropyLoss(weight=torch.tensor(turtle_weights['image_id'].values, dtype=torch.float).to(device))\n",
        "cross_entropy = nn.CrossEntropyLoss(label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2hA1aQCQx3",
        "outputId": "03cba79c-e0b3-41c3-8059-f781fe32bbba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=3, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=101, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model_conv.to(device)\n",
        "model_conv.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR1tMDiQ63zt"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "v78qtVsa63zt"
      },
      "outputs": [],
      "source": [
        "top_k_precisions = []\n",
        "epoch_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Mmu96bY63zt"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76e9b85-120c-4fa8-e5ea-225271b39271",
        "tags": [],
        "id": "CHDJVTBh63zt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - MAP@k : 0.148148 - Learning Rate : 0.000149: 100%|| 6/6 [02:56<00:00, 29.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - MAP@k : 0.067166 - Loss 4.587697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - MAP@k : 0.133333 - Learning Rate : 0.000257: 100%|| 6/6 [02:49<00:00, 28.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - MAP@k : 0.213070 - Loss 4.314307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - MAP@k : 0.111111 - Learning Rate : 0.000366: 100%|| 6/6 [02:43<00:00, 27.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - MAP@k : 0.252514 - Loss 4.041402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - MAP@k : 0.277778 - Learning Rate : 0.000475: 100%|| 6/6 [02:44<00:00, 27.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - MAP@k : 0.301005 - Loss 3.833157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - MAP@k : 0.296296 - Learning Rate : 0.000583: 100%|| 6/6 [02:44<00:00, 27.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - MAP@k : 0.363776 - Loss 3.571577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - MAP@k : 0.259259 - Learning Rate : 0.000692: 100%|| 6/6 [02:46<00:00, 27.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - MAP@k : 0.416756 - Loss 3.318512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - MAP@k : 0.161111 - Learning Rate : 0.000801: 100%|| 6/6 [02:43<00:00, 27.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - MAP@k : 0.465111 - Loss 3.054862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - MAP@k : 0.703704 - Learning Rate : 0.000909: 100%|| 6/6 [02:46<00:00, 27.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - MAP@k : 0.626968 - Loss 2.787710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - MAP@k : 0.500000 - Learning Rate : 0.000982: 100%|| 6/6 [02:45<00:00, 27.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - MAP@k : 0.632416 - Loss 2.564761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 - MAP@k : 0.833333 - Learning Rate : 0.000873: 100%|| 6/6 [02:42<00:00, 27.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - MAP@k : 0.723736 - Loss 2.372948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 - MAP@k : 0.666667 - Learning Rate : 0.000765: 100%|| 6/6 [02:42<00:00, 27.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - MAP@k : 0.726964 - Loss 2.190976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 - MAP@k : 0.666667 - Learning Rate : 0.000656: 100%|| 6/6 [02:42<00:00, 27.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - MAP@k : 0.757585 - Loss 2.064105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 - MAP@k : 0.629630 - Learning Rate : 0.000547: 100%|| 6/6 [02:38<00:00, 26.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - MAP@k : 0.772999 - Loss 1.908816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 - MAP@k : 0.703704 - Learning Rate : 0.000438: 100%|| 6/6 [02:37<00:00, 26.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - MAP@k : 0.798154 - Loss 1.802985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 - MAP@k : 0.777778 - Learning Rate : 0.000330: 100%|| 6/6 [02:37<00:00, 26.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - MAP@k : 0.818849 - Loss 1.730219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 - MAP@k : 0.911111 - Learning Rate : 0.000221: 100%|| 6/6 [02:37<00:00, 26.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - MAP@k : 0.845992 - Loss 1.682729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 - MAP@k : 0.888889 - Learning Rate : 0.000112: 100%|| 6/6 [02:38<00:00, 26.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - MAP@k : 0.846786 - Loss 1.631589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 - MAP@k : 0.870370 - Learning Rate : 0.000039: 100%|| 6/6 [02:41<00:00, 26.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - MAP@k : 0.843575 - Loss 1.611681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 - MAP@k : 0.759259 - Learning Rate : 0.000036: 100%|| 6/6 [02:40<00:00, 26.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - MAP@k : 0.827281 - Loss 1.598838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 - MAP@k : 1.000000 - Learning Rate : 0.000032: 100%|| 6/6 [02:47<00:00, 27.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - MAP@k : 0.868229 - Loss 1.592855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 - MAP@k : 0.888889 - Learning Rate : 0.000029: 100%|| 6/6 [02:42<00:00, 27.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - MAP@k : 0.850329 - Loss 1.582913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 - MAP@k : 0.666667 - Learning Rate : 0.000026: 100%|| 6/6 [02:43<00:00, 27.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - MAP@k : 0.814464 - Loss 1.568614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 - MAP@k : 0.833333 - Learning Rate : 0.000022: 100%|| 6/6 [02:40<00:00, 26.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - MAP@k : 0.841347 - Loss 1.569042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24 - MAP@k : 0.666667 - Learning Rate : 0.000019: 100%|| 6/6 [02:36<00:00, 26.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - MAP@k : 0.815278 - Loss 1.560762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25 - MAP@k : 1.000000 - Learning Rate : 0.000016: 100%|| 6/6 [02:38<00:00, 26.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - MAP@k : 0.869661 - Loss 1.559842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26 - MAP@k : 0.777778 - Learning Rate : 0.000013: 100%|| 6/6 [02:40<00:00, 26.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - MAP@k : 0.833514 - Loss 1.552679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27 - MAP@k : 0.777778 - Learning Rate : 0.000009: 100%|| 6/6 [02:37<00:00, 26.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - MAP@k : 0.833297 - Loss 1.549473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28 - MAP@k : 0.888889 - Learning Rate : 0.000006: 100%|| 6/6 [02:38<00:00, 26.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - MAP@k : 0.852765 - Loss 1.547779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29 - MAP@k : 0.361111 - Learning Rate : 0.000003: 100%|| 6/6 [02:39<00:00, 26.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - MAP@k : 0.764856 - Loss 1.548799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30 - MAP@k : 0.722222 - Learning Rate : -0.000001: 100%|| 6/6 [02:39<00:00, 26.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - MAP@k : 0.823897 - Loss 1.548911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(30):\n",
        "    \n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "    pbar = tqdm.tqdm(data_loader)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for sample in pbar:\n",
        "        optimizer_model.zero_grad() \n",
        "        with autocast():\n",
        "            op, aux_op = model_conv(sample['img'].to(device))\n",
        "            loss1 = cross_entropy(op, sample['id'].to(device))\n",
        "            loss2 = cross_entropy(aux_op, sample['orientation'].to(device))\n",
        "            loss = loss1 + 0.4*loss2\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_model)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "        running_loss += loss1.item() * sample['img'].size(0)\n",
        "        top_k_precision = mapk(sample['id'], op.topk(5, dim=1).indices)\n",
        "        top_k_precisions.append(top_k_precision)\n",
        "        pbar.set_description('Epoch %d - MAP@k : %f - Learning Rate : %f' % (epoch+1, top_k_precision, lr_scheduler.get_last_lr()[0]))\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print('Epoch %d - MAP@k : %f - Loss %f' % (epoch+1, np.mean(top_k_precisions[-num_epoch_steps:]), epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "nQPqYA_N63zu",
        "outputId": "c85ca12f-f425-45cd-dd2c-7abd6196e6f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4ac29e090>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(epoch_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "4fhV_ohR63zu",
        "outputId": "7ec0092a-66bb-466c-e17c-672d6275a3a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4aabcff10>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(top_k_precisions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnYrBT_N63zu"
      },
      "source": [
        "### Validation on extra images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLp2YNN163zu"
      },
      "outputs": [],
      "source": [
        "extra_dataset = TurtleDataSet(IMAGE_DIR, extra,turtle_ids, transform=img_transform, include_orientation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhzLZ2YC63zu",
        "outputId": "d786436b-efc8-44bf-ba93-3d4a8f64a6fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=3, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=101, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model_conv.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8NGH1p463zu",
        "outputId": "280d36f3-ed87-4593-b852-b8fd97c02153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 84/84 [11:22<00:00,  8.13s/it]\n"
          ]
        }
      ],
      "source": [
        "data_loader = torch.utils.data.DataLoader(extra_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
        "pbar = tqdm.tqdm(data_loader)\n",
        "model_conv.eval()\n",
        "preds = []\n",
        "image_ids = []\n",
        "val_precisions = []\n",
        "with torch.no_grad():\n",
        "    for sample in pbar:\n",
        "        out = model_conv(sample['img'].to(device))\n",
        "        # break\n",
        "        top_k_precision = mapk(sample['id'], out.topk(5, dim=1).indices)\n",
        "        val_precisions.append(top_k_precision)\n",
        "        pred = out.topk(5, dim=1).indices.cpu().numpy()\n",
        "        preds.append(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzpWdCcz63zv",
        "outputId": "ab613164-3dc3-415c-9896-8531f57c1e7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7580047123015874"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "np.mean(val_precisions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gty5EfAK63zv"
      },
      "outputs": [],
      "source": [
        "reserved_mem = torch.cuda.memory_reserved(0)\n",
        "allocated_mem = torch.cuda.memory_allocated(0)\n",
        "\n",
        "mem_use = allocated_mem/reserved_mem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qknDp7ln63zv",
        "outputId": "5ec74157-9087-414f-c354-ce0839d4b505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.020576755355738992"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "mem_use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTYBri-W63zv"
      },
      "source": [
        "## As Margin Maximization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jpRzjzx63zv"
      },
      "source": [
        "### Dataset for Embedding Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0OFkbCGK63zv"
      },
      "outputs": [],
      "source": [
        "# Dataset to generate triplets (anchor, positive, negative) for training\n",
        "class EmbeddingDataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, labels_df, num_samples, easy_mode=False, transform=None):\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.df = labels_df\n",
        "        self.num_samples = num_samples\n",
        "        self.samples = self.generate_samples(self.df, self.num_samples, easy_mode)\n",
        "        self.easy_mode = easy_mode\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_samples(df, num_samples, easy_mode):\n",
        "\n",
        "        def make_dictionary_for_turtle_classes(df, easy_mode):\n",
        "            \n",
        "            turtle_classes = {}\n",
        "            if easy_mode:\n",
        "                orientations = df['image_location'].unique().tolist()\n",
        "\n",
        "                for turtle_id in df['turtle_id'].unique():\n",
        "                    turtle_classes[turtle_id] = {}\n",
        "                    for orientation in orientations:\n",
        "                      turtle_image_ids = df[(df['turtle_id']==turtle_id) & (df['image_location']==orientation)]['image_id'].tolist()\n",
        "                      turtle_classes[turtle_id][orientation]=turtle_image_ids\n",
        "            else:\n",
        "              for turtle_id in df['turtle_id'].unique():\n",
        "                turtle_image_ids = df[df['turtle_id']==turtle_id]['image_id'].tolist()\n",
        "                turtle_classes[turtle_id]=turtle_image_ids\n",
        "            return turtle_classes\n",
        "\n",
        "        samples = []\n",
        "        classes = df['turtle_id'].unique()\n",
        "        turtle_classes = make_dictionary_for_turtle_classes(df, easy_mode)\n",
        "\n",
        "        for _ in range(num_samples):\n",
        "\n",
        "            '''\n",
        "              - randomly choose anchor, positive and negative images for triplet loss\n",
        "              - anchor and positive images in pos_class\n",
        "              - negative image in neg_class\n",
        "              - at least, two images needed for anchor and positive images in pos_class\n",
        "              - negative image should have different class as anchor and positive images by definition\n",
        "            '''\n",
        "            is_positive_sample = random.choice([True, False])\n",
        "            \n",
        "            # print(turtle_classes)\n",
        "            if is_positive_sample:\n",
        "                pos_class = turtle_classes[np.random.choice(classes)]\n",
        "                if easy_mode:\n",
        "                    # Randomly choose an orientation\n",
        "                    orientations = list(pos_class.keys())\n",
        "                    # We want to train on turtles which have at least been photographed from orientations\n",
        "                    while len(orientations) < 2:\n",
        "                        pos_class = turtle_classes[np.random.choice(classes)]\n",
        "                        orientations = list(pos_class.keys())\n",
        "                    \n",
        "                    orientation = random.choice(orientations)\n",
        "                    while len(pos_class[orientation])<2:\n",
        "                        orientation = random.choice(orientations)\n",
        "                    image_ids = np.random.choice(pos_class[orientation], 2, replace=False)\n",
        "                else:\n",
        "                    # print(pos_class)\n",
        "                    while len(pos_class)<2:\n",
        "                        pos_class = turtle_classes[np.random.choice(classes)]\n",
        "                    image_ids = np.random.choice(pos_class, 2, replace=False)\n",
        "                sample = (image_ids[0], image_ids[1], 1)\n",
        "            else:\n",
        "                pos_class = turtle_classes[np.random.choice(classes)]\n",
        "                neg_class = turtle_classes[np.random.choice(classes)]\n",
        "                \n",
        "                if easy_mode:\n",
        "                    # Randomly choose an orientation\n",
        "                    orientation = random.choice(list(pos_class.keys()))\n",
        "                    pos_id = np.random.choice(pos_class[orientation], 1, replace=False)\n",
        "                    \n",
        "                    # REsample a negative class if the same orientation is not available\n",
        "                    while orientation not in neg_class.keys():\n",
        "                        neg_class = np.random.choice(classes)\n",
        "                        \n",
        "                    neg_id = np.random.choice(neg_class[orientation], 1, replace=False)\n",
        "                    \n",
        "                else:\n",
        "                    \n",
        "                    pos_id = np.random.choice(pos_class, 1, replace=False)\n",
        "                    neg_id = np.random.choice(neg_class, 1, replace=False)\n",
        "                    \n",
        "                sample = (pos_id[0], neg_id[0], -1)\n",
        "            \n",
        "            \n",
        "\n",
        "            samples.append(sample)\n",
        "                \n",
        "\n",
        "        return samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        id1, id2, y = self.samples[idx]\n",
        "\n",
        "        img1 = os.path.join(self.root_dir, id1 +'.JPG')\n",
        "        img2 = os.path.join(self.root_dir, id2 +'.JPG')\n",
        "\n",
        "        img1 = Image.open(img1)\n",
        "        img2 = Image.open(img2)\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        return img1, img2, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "UtMY9xcr63zw"
      },
      "outputs": [],
      "source": [
        "# Since this model was pretrained above\n",
        "# We want to freeze all weights\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnZbbDC3JsG2",
        "outputId": "10cad290-4649-457c-dabd-ced5013d0961"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=3, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=101, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "hzCcZtT763zw"
      },
      "outputs": [],
      "source": [
        "# Add a few new layers to replace the old classifier\n",
        "num_ftrs = model_conv.fc[0].in_features\n",
        "model_conv.fc = nn.Sequential(nn.Linear(num_ftrs, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU())\n",
        "# model_conv.classifier[6] = nn.Linear(num_ftrs,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_hXV7YU63zw"
      },
      "outputs": [],
      "source": [
        "for param in model_conv.classifier.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbHoyg-b63zw"
      },
      "source": [
        "### Cosine Embedding Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "71nursv163zx"
      },
      "outputs": [],
      "source": [
        "cosine_loss = nn.CosineEmbeddingLoss(margin=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dXxs7BYA63zx",
        "outputId": "b1d33de7-ce38-40d2-f0ea-a4a12cb38222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=3, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "model_conv.to(device)\n",
        "model_conv.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BaYUa40563zx"
      },
      "outputs": [],
      "source": [
        "num_training_samples = 4096\n",
        "batch_size=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "i4GRrrkU63zx"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()\n",
        "\n",
        "optimizer_model = optim.AdamW(filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "                             lr=0.001, weight_decay=0.001)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_model,\n",
        "                                                   max_lr=0.001,\n",
        "                                                   anneal_strategy='linear',\n",
        "                                                   epochs=10,\n",
        "                                                   steps_per_epoch=int(num_training_samples/batch_size),\n",
        "                                                   three_phase=True\n",
        "                                                   \n",
        "                                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "tags": [],
        "id": "zC8G8h9D63zx"
      },
      "outputs": [],
      "source": [
        "epoch_losses = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI7-wp-L63zy"
      },
      "source": [
        "#### Easy Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7f9877-38fc-4ca9-8521-8f16402e4ac4",
        "tags": [],
        "id": "prUBhcjM63zy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Loss : 0.243490 - Learning Rate : 0.000363: 100%|| 32/32 [09:18<00:00, 17.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss 0.245868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Loss : 0.224871 - Learning Rate : 0.000687: 100%|| 32/32 [08:49<00:00, 16.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Loss 0.248206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Loss : 0.248781 - Learning Rate : 0.000990: 100%|| 32/32 [08:55<00:00, 16.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Loss 0.241937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Loss : 0.202807 - Learning Rate : 0.000667: 100%|| 32/32 [08:59<00:00, 16.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Loss 0.224454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Loss : 0.187940 - Learning Rate : 0.000343: 100%|| 32/32 [08:54<00:00, 16.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Loss 0.215974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Loss : 0.192449 - Learning Rate : 0.000039: 100%|| 32/32 [08:37<00:00, 16.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Loss 0.214793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Loss : 0.221104 - Learning Rate : 0.000029: 100%|| 32/32 [08:42<00:00, 16.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Loss 0.214480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Loss : 0.221331 - Learning Rate : 0.000020: 100%|| 32/32 [08:41<00:00, 16.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Loss 0.220609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Loss : 0.235930 - Learning Rate : 0.000010: 100%|| 32/32 [08:33<00:00, 16.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Loss 0.216296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 - Loss : 0.196655 - Learning Rate : -0.000000: 100%|| 32/32 [08:34<00:00, 16.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Loss 0.212067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    dataset = EmbeddingDataset(IMAGE_DIR, train, num_training_samples, transform=img_transform, easy_mode=True)\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "    pbar = tqdm.tqdm(data_loader)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for sample in pbar:\n",
        "        img1, img2, y =  sample\n",
        "        optimizer_model.zero_grad() \n",
        "        with autocast():\n",
        "            op1, _ = model_conv(img1.to(device))\n",
        "            op2, _ = model_conv(img2.to(device))\n",
        "            loss = cosine_loss(op1, op2, y.to(device))\n",
        "            # loss = cross_entropy(op, sample['id'].to(device))\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_model)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "        running_loss += loss.item() * img1.size(0)\n",
        "        pbar.set_description('Epoch %d - Loss : %f - Learning Rate : %f' % (epoch+1, loss.item(), lr_scheduler.get_last_lr()[0]))\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print('Epoch %d - Loss %f' % (epoch+1, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "-LqpPvro63zy",
        "outputId": "2e4d58df-12b0-4f0f-9d9e-dd2058fedb78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2254682925529778"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "np.mean(epoch_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "77PwBHXN63zy",
        "outputId": "8b4d293f-8370-4f47-8aa6-6291a23067b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2254682925529778"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "np.mean(epoch_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "X5O9KiiF63zy",
        "outputId": "5a06d3d6-9eff-4bae-e4c1-eecf501965f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f942b65a890>]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+VhCSQENawZGHf18REFhfcUHEjWBdAcakotYp1abW29unTxz72p2Itan2suGtFFKpCK4jVYl0qS4CwhDWAkgVI2ElC9uv3x5zgEAMZyCQnmbner1de5NznzJnrjOZ859xnuUVVMcYYE3xC3C7AGGOMOywAjDEmSFkAGGNMkLIAMMaYIGUBYIwxQcoCwBhjgpRPASAi40Rks4hkicjDtcx/QEQ2iMhaEflMRLp7zasUkQznZ4FXe08RWeas810RCffPJhljjPGF1HUfgIiEAluAi4EcYAUwWVU3eC1zAbBMVYtF5KfA+ao60ZlXqKrRtaz3PeB9VZ0jIn8B1qjqC/7aMGOMMSfnyxHACCBLVberahkwB0jzXkBVl6hqsTO5FEg42QpFRIALgXlO0xvAhFMp3BhjTP2E+bBMPJDtNZ0DjDzJ8lOBRV7TkSKSDlQAj6vqh0AH4KCqVnitM762lYnINGAaQFRUVMqAAQN8KNkYY0y1lStX7lXV2JrtvgSAz0RkCpAKnOfV3F1Vc0WkF/AvEVkHHPJ1nao6C5gFkJqaqunp6f4s2RhjAp6IfFdbuy9dQLlAotd0gtNW8w3GAo8A41W1tLpdVXOdf7cDnwPJwD6grYhUB1Ct6zTGGNNwfAmAFUBf56qdcGASsMB7ARFJBl7Es/PP92pvJyIRzu8dgbOBDeo587wEuNZZ9BZgfn03xhhjjO/qDACnn346sBjYCLynqpki8qiIjHcWmwFEA3NrXO45EEgXkTV4dviPe1099EvgARHJwnNO4BW/bZUxxpg61XkZaFNi5wCMMebUichKVU2t2W53AhtjTJCyADDGmCBlAWCMMUHKAqCRHCgqY/aynazP9fkWCGOMaVB+vRHMHK+isoovt+5l7spsPt2QT1llFVHhobw5dSQp3du5XZ4xJshZADSArPxC5q7M5oNVueQfKaV9VDhTRnVn7MBOPPLhem59dTlv3T6SpMS2bpdqjAliFgB+criknH+s2cXcldms3nmQ0BDhgv6xXJuSyIUDOhEe5ultm33HSCbNWspNryzj7dtHMizBQsAY4w67D6AeqqqU/2zbx9yV2Xy8fjelFVX06xzNdSmJTEiOJ7Z1RK2vyzt4lImzvuFQcTmz7xjFkPg2jVy5MSaYnOg+AAuA07BzXzHzVmbzt1W55B48SkxkGOOT4rguJZFhCW3wPO365HIOFDPxxaUUllYw+46RDI6zEDDGNAwLgHoqKq1g0frdzE3PZtmO/YjAuX1juS4lgYsHdSayRegprzN7fzETX/yGo+WVzL5jFAO7xjRA5caYYGcBcBpUlRXfHmBuejYL1+2iqKySnh2juDYlgR+dEU/XNi3r/R7f7Sti0qyllFZU8c4do+jfpbUfKjfGmO9ZAJyCvINHeX9VDvNW5vDtvmKiwkO5clgc16UmkNK9nU9dPKdix94iJs36hsoq5Z07RtG3s4WAMcZ/LADqUFJeyeLM3cxbmcNXWXtRhdG9OnBtSgKXDe1Cq/CGvWBqW0Ehk2YtRRXmTBtFn04/GEbZGGNOiwVALVSVjOyDzFuZw4I1eRwpqSC+bUuuTUng2pQEEtu38tt7+SIr3xMCIeIJgV6xFgLGmPqzAPCSf6SED1blMm9lDlvzC4lsEcJlQ7pyXUoCo3p1ICTEv108p2LLniNMnrWUsFDh3Wmj6dExyrVajDGBIegDoKyiis827mHeyhw+31JAZZWS0r0d16UkcMWwrrSObOHnak/fpt2HueGlZUSEhfDutNF069C4RyLGmMAS1AHw9D+38NY333KguJzOMRH86AxPF0/vJtzFsiHvMDe8vJSo8DDmTBvV6N1RxpjAcaIACIpHQRSVVnBWn45cl5LAuX1jCXWxi8dXg+Ji+OvUkdz48jImv7SUOdNGkdDOQsAY4z9BcQTQnK3LOcQNLy+lXatw5kwbRVzb+t97YIwJLvUaElJExonIZhHJEpGHa5n/gIhsEJG1IvKZiHSvMT9GRHJE5M9ebZ8768xwfjqdzoYFuqEJbfjr1JEcKCpj8ktL2X2oxO2SjDEBos4AEJFQ4HngMmAQMFlEBtVYbDWQqqrDgHnAkzXm/x74opbV36iqSc5P/ilXHySGJ7bljakj2FfoCYH8wxYCxpj68+UIYASQparbVbUMmAOkeS+gqktUtdiZXAokVM8TkRSgM/CJf0oOTmd0a8cbt51J/uESJr20lPwjFgLGmPrxJQDigWyv6Ryn7USmAosARCQE+CPwixMs+5rT/fNfcoLnK4jINBFJF5H0goICH8oNXCnd2/P6bSPYfaiEG15axt7CUrdLMsY0Y34dE1hEpgCpwAyn6S5goarm1LL4jao6FDjX+bmptnWq6ixVTVXV1NjYWH+W2yyd2aM9r956JrkHjnLDS0vZZyFgjDlNvgRALpDoNZ3gtB1HRMYCjwDjVbV6rzQamC4i3wJPATeLyOMAqprr/HsEmI2nq8n4YFSvDrxyayo79xdz48vL2F9U5nZJxphmyJcAWAH0FZGeIhIOTAIWeC8gIsnAi3h2/sdO5qrqjaraTVV74OkGelNVHxaRMBHp6Ly2BXAlsN4vWxQkzurdkZdvPpMde4uY8vIyDhZbCBhjTk2dAaCqFcB0YDGwEXhPVTNF5FERGe8sNgOIBuY6ffoLTrC6ahHAYhFZC2TgOaJ46XQ3Ilid07cjs25OJaugkCmvLONQcbnbJRljmhG7ESwALNmUz0/eWsmArq15a+pI2rRsOs81Msa4r143gpmm7YIBnXhhyhls3HWYm19dzuESOxIwxtTNAiBAXDSwM8/fcAaZuYe49dXlFJZWuF2SMaaJswAIIJcM7sKfb0hmTY4nBIosBIwxJ2EBEGDGDenKs5OSWZ19kB+/voLiMgsBY0ztLAAC0BXDujJzYhLp3+7nttdXcLSs0u2SjDFNkAVAgLpqeBx/mpjE8h37uf3NFZSUWwgYY45nARDA0pLimXHtcP6zbR93vJluIWCMOY4FQIC7JiWBJ64ZxldZe/nJWystBIwxx1gABIHrUxP5f1cP5d9bCrjr7VWUVlgIGGMsAILGpBHdeOzqIfxrUz53v72Ksooqt0syxrjMAiCI3DiyO79PG8ynG/N5/T873C7HGOMyC4Agc9PoHiR3a8v7q37wRG9jTJCxAAhCacPj2LT7CJt3H3G7FGOMiywAgtAVw+IIDRHmZ9hRgDHBzAIgCMW2juDsPh2Zn5FHc3ocuDHGvywAgtSEpDhyDx5l5XcH3C7FGOMSC4AgdcngLkS2CGF+Rp7bpRhjXGIBEKSiI8IYO7AzH63bRXml3RNgTDDyKQBEZJyIbBaRLBF5uJb5D4jIBhFZKyKfiUj3GvNjRCRHRP7s1ZYiIuucdT4rIlL/zTGnYkJSPPuLyvhya4HbpRhjXFBnAIhIKPA8cBkwCJgsIoNqLLYaSFXVYcA84Mka838PfFGj7QXgDqCv8zPulKs39TKmXyxtW7WwbiBjgpQvRwAjgCxV3a6qZcAcIM17AVVdoqrFzuRSIKF6noikAJ2BT7zaugIxqrpUPZehvAlMqNeWmFMWHhbC5UO78knmHhs9zJgg5EsAxAPZXtM5TtuJTAUWAYhICPBH4Be1rDPHl3WKyDQRSReR9IIC66rwt7ThcRwtr+TTjXvcLsUY08j8ehJYRKYAqcAMp+kuYKGq5pz4VSenqrNUNVVVU2NjY/1RpvFyZo/2xLWJ5MPVdlOYMcEmzIdlcoFEr+kEp+04IjIWeAQ4T1VLnebRwLkichcQDYSLSCHwDF7dRCdap2l4ISHCVUlxvPzlDvYVltIhOsLtkowxjcSXI4AVQF8R6Ski4cAkYIH3AiKSDLwIjFfV/Op2Vb1RVbupag883UBvqurDqroLOCwio5yrf24G5vtnk8ypmpAUT2WVsnDdLrdLMcY0ojoDQFUrgOnAYmAj8J6qZorIoyIy3llsBp5v+HNFJENEFpxgdd7uAl4GsoBtOOcNTOMb0KU1/TpH29VAxgQZX7qAUNWFwMIabb/1+n2sD+t4HXjdazodGOJjnaYBiYhn/ODFm8neX0xi+1Zul2SMaQR2J7ABYPzwOAAWrLGjAGOChQWAASCxfStSu7djfkauPSHUmCBhAWCOSUuKY8ueQjbZQDHGBAULAHPMFcPiCAsRPrSBYowJChYA5pj2UeGc27cjf8/Io6rKuoGMCXQWAOY4E5LjyTtUwopv97tdijGmgVkAmONcPKgzLVuE8qHdE2BMwLMAMMdpFR7GJYM7s3DdLsoqbKAYYwKZBYD5gQlJ8Rw6Ws6/t9jTV40JZBYA5gfO6duR9lHhzLergYwJaBYA5gdahIZwxdCufLpxD4U2UIwxAcsCwNQqLSmOkvIqPsnc7XYpxpgGYgFgapXSvR0J7Vra1UDGBDALAFMrEWH88Di+ztpLwZHSul9gjGl2LADMCU1I9gwU89FaOwowJhBZAJgT6te5NQO6tGa+PSLamIBkAWBOakJyPKt3HuS7fUVul2KM8TMLAHNSV1UPFGMng40JOD4FgIiME5HNIpIlIg/XMv8BEdkgImtF5DMR6e60dxeRVc44wZkicqfXaz531pnh/HTy32YZf4lv25IRPdvzoQ0UY0zAqTMARCQUeB64DBgETBaRQTUWWw2kquowYB7wpNO+CxitqknASOBhEYnzet2Nqprk/OTXc1tMA0lLimNbQRGZeYfdLsUY40e+HAGMALJUdbuqlgFzgDTvBVR1iaoWO5NLgQSnvUxVq68hjPDx/UwTc/mQrrQIFXs0hDEBxpcdcjyQ7TWd47SdyFRgUfWEiCSKyFpnHU+oqndn8mtO989/iYjUtjIRmSYi6SKSXlBgDydzQ7uocM7rF8uCNXlU2kAxxgQMv34jF5EpQCowo7pNVbOdrqE+wC0i0tmZdaOqDgXOdX5uqm2dqjpLVVNVNTU2Ntaf5ZpTkJYUz57DpSzbsc/tUowxfuJLAOQCiV7TCU7bcURkLPAIMN6r2+cY55v/ejw7e1Q11/n3CDAbT1eTaaLGDuxMVHgo81fb1UDGBApfAmAF0FdEeopIODAJWOC9gIgkAy/i2fnne7UniEhL5/d2wDnAZhEJE5GOTnsL4Eo84WCaqJbhoVw6uAsL1++itKLS7XKMMX5QZwCoagUwHVgMbATeU9VMEXlURMY7i80AooG5Tp9+dUAMBJaJyBrg38BTqroOzwnhxc65gQw8RxQv+XPDjP+lJcdzpKSCJZvsXIwxgSDMl4VUdSGwsEbbb71+H3uC1/0TGFZLexGQckqVGted3bsDHaPDWbAml3FDurhdjjGmnuyyTOOzsNAQrhwWx6cb8zlcUu52OcaYerIAMKdkfFIcZRVVLF5vA8UY09xZAJhTkpzYlm7tWzHfng1kTLNnAWBOiYiQlhTHf7btJf9widvlGGPqwQLAnLK0pDiqFP6+dpfbpRhj6sECwJyyPp1aMzguxp4NZEwzZwFgTsuEpHjW5hxie0Gh26UYY06TBYA5LVcNj0MEOxlsTDNmAWBOS5c2kYzq2YEFa/JsoBhjmikLAHPa0pLi2LG3iLU5h9wuxRhzGiwAzGm7bGhXwkNDrBvImGbKAsCctjYtW3DBgFj+vtYGijGmObIAMPWSlhRPwZFSvtlmA8UY09xYAJh6uXBAJ1pHhPGh3RNgTLNjAWDqJbJFKJcO6cLH63dTUm4DxRjTnFgAmHqbkBRPYWkF/9qUX/fCxpgmwwLA1Nvo3h2IbR1hj4YwppmxADD1FhoiXDUsjiWbCjhUbAPFGNNcWAAYv0hLiqOssoqPM+0JocY0Fz4FgIiME5HNIpIlIg/XMv8BEdkgImtF5DMR6e60dxeRVc5A8ZkicqfXa1JEZJ2zzmdFRPy3WaaxDUtoQ8+OUXy42m4KM6a5qDMARCQUeB64DBgETBaRQTUWWw2kquowYB7wpNO+CxitqknASOBhEYlz5r0A3AH0dX7G1XNbjItEhPHD41i6Yx+7D9lAMcY0B74cAYwAslR1u6qWAXOANO8FVHWJqhY7k0uBBKe9TFVLnfaI6vcTka5AjKouVc+TxN4EJtR7a4yr0pLiUIW/r7GjAGOaA18CIB7I9prOcdpOZCqwqHpCRBJFZK2zjidUNc95fY4v6xSRaSKSLiLpBQUFPpRr3NIrNpphCW3spjBjmgm/ngQWkSlAKjCjuk1Vs52uoT7ALSLS+VTWqaqzVDVVVVNjY2P9Wa5pAGlJ8WTmHSYr/4jbpRhj6uBLAOQCiV7TCU7bcURkLPAIMN6r2+cY55v/euBc5/UJda3TND9XDetKiA0UY0yz4EsArAD6ikhPEQkHJgELvBcQkWTgRTw7/3yv9gQRaen83g44B9isqruAwyIyyrn652Zgvl+2yLiqU0wkZ/XuyPwMGyjGmKauzgBQ1QpgOrAY2Ai8p6qZIvKoiIx3FpsBRANznUs+qwNiILBMRNYA/waeUtV1zry7gJeBLGAbXucNTPOWlhTHzv3FrM4+6HYpxpiTkOb0LS01NVXT09PdLsPU4XBJOan/+yk3jOjG78YPdrscY4KeiKxU1dSa7XYnsPG7mMgWjB3YiX+szaOissrtcowxJ2ABYBrE+OHx7C0s42sbKMaYJssCwDSICwbE0joyjPmr7eIuY5oqCwDTICLCQrl8SFcWZ+7maJkNFGNMU2QBYBpMWnIcRWWVfLpxj9ulGGNqYQFgGszInh3oHGMDxRjTVFkAmAYTGuJ5Qujnmws4UFTmdjnGmBosAEyDSkuKp6JKWbjeBooxpqmxADANanBcDL1jo+zZQMY0QRYApkGJCGlJ8SzfsZ/cg0fdLscY48UCwDS4tCTPIHA2UIwxTYsFgGlw3TtEkZTYlg/tpjBjmhQLANMoJiTFsWn3ETbvtoFijGkqLABMo7hiWByhIWL3BBjThFgAmEYR2zqCs/vYQDHGNCUWAKbRTEiKI/fgUVZ+d8DtUowxWACYRnTJ4C5EtgixewKMaSIsAEyjiY4IY+zAzny0bhflNlCMMa7zKQBEZJyIbBaRLBF5uJb5D4jIBhFZKyKfiUh3pz1JRL4RkUxn3kSv17wuIjucMYQzRCTJf5tlmqq0pHj2F5Xx5dYCt0sxJujVGQAiEgo8D1wGDAImi8igGoutBlJVdRgwD3jSaS8GblbVwcA4YKaItPV63YOqmuT8ZNRzW0wzcF6/WNq0bGHdQMY0Ab4cAYwAslR1u6qWAXOANO8FVHWJqhY7k0uBBKd9i6pudX7PA/KBWH8Vb5qf8LAQLh/alU8y91BUWuF2OcYENV8CIB7I9prOcdpOZCqwqGajiIwAwoFtXs2POV1DfxKRiNpWJiLTRCRdRNILCqzbIBBMSIrjaLkNFGOM2/x6ElhEpgCpwIwa7V2Bt4Afq2r12b9fAQOAM4H2wC9rW6eqzlLVVFVNjY21g4dAcGaP9sS1ibRHQxjjMl8CIBdI9JpOcNqOIyJjgUeA8apa6tUeA3wEPKKqS6vbVXWXepQCr+HpajJBICREuCopji+27qXgSGndLzDGNAhfAmAF0FdEeopIODAJWOC9gIgkAy/i2fnne7WHAx8Ab6rqvBqv6er8K8AEYH19NsQ0L9elJCLAf3243u4MNsYldQaAqlYA04HFwEbgPVXNFJFHRWS8s9gMIBqY61zSWR0Q1wNjgFtrudzzbRFZB6wDOgL/67/NMk1dn07RPHhpfz7O3M3s5TvdLseYoCTN6dtXamqqpqenu12G8ZOqKuWW15azfMd+Fkw/h/5dWrtdkjEBSURWqmpqzXa7E9i4JiRE+OP1w2kdGcY976yipLzS7ZKMCSoWAMZVnVpH8sfrk9iyp5Df/2OD2+UYE1QsAIzrzusXy7QxvXh72U4WrdvldjnGBA0LANMk/OKS/gxPaMMv/7bWBo83ppFYAJgmITwshGcnJ1OlcO87q6mwp4Ua0+AsAEyT0b1DFP87YQjp3x3g2c+2ul2OMQHPAsA0KROS47nmjASeW5LFN9v2uV2OMQHNAsA0OY+mDaZHhyjufzeDA0VlbpdjTMCyADBNTlREGM9NTmZfUSkPzltjj4owpoFYAJgmaUh8Gx6+bCCfbsznzW++c7scYwKSBYBpsm47uwcXDujEYws3siHvsNvlGBNwLABMkyUizLh2GG1btuCed1ZRXGYjiBnjTxYApknrEB3BzIlJbN9bxP8ssEdFGONPFgCmyTurT0fuOr8376Zn8/c1Npi8Mf5iAWCahfvG9iO5W1t+/f46svcXu12OMQHBAsA0Cy1CQ3h2UjII3PPOasrtURHG1JsFgGk2Etu34vEfDSMj+yBP/3OL2+UY0+xZAJhm5YphXZl0ZiJ/+fc2vtq61+1yTAOoqlLe+uZbVn53wO1SAp5PASAi40Rks4hkicjDtcx/QEQ2iMhaEflMRLo77Uki8o2IZDrzJnq9pqeILHPW+a4zgLwxdfrvqwbTOzaa+9/LYG9hqdvlGD+qqlIe+XAd/zU/k+v+8h9mLN5EWYV19zWUOgNAREKB54HLgEHAZBEZVGOx1UCqqg4D5gFPOu3FwM2qOhgYB8wUkbbOvCeAP6lqH+AAMLW+G2OCQ8vwUJ6bnMyho+X8Yu4aqqrsURGBoKpK+dX763hneTY/Oa8X16Yk8PySbfzoha/Jyj/idnkByZcjgBFAlqpuV9UyYA6Q5r2Aqi5R1epLM5YCCU77FlXd6vyeB+QDsSIiwIV4wgLgDWBCfTfGBI+BXWP4zRUD+XxzAa9+vcPtckw9VVYpD/1tLe+mZ/Ozi/ry8LgBPHntcP4yJYW8gyVc8exXvP71Dgt7P/MlAOKBbK/pHKftRKYCi2o2isgIIBzYBnQADqpq9a2dda3TmB+4aVR3Lh7UmSc+3sS6nENul2NOU2WV8tC8tcxbmcN9Y/vywMX98HxHhHFDuvDxfedyVu8O/O7vG7jlteXsPlTicsWBw68ngUVkCpAKzKjR3hV4C/ixqp5Sh56ITBORdBFJLygo8F+xptkTEZ68ZhgdoyO4551VFJbaoyKam8oq5cG5a/jbqhzuH9uP+8b2+8EynVpH8uqtZ3oGC/r2AJfO/IKP1trY0f7gSwDkAole0wlO23FEZCzwCDBeVUu92mOAj4BHVHWp07wPaCsiYSdbJ4CqzlLVVFVNjY2N9aFcE0zaRYUzc2ISO/cX89v5690ux5yCisoqfv5eBu+vzuXnF/fj3rF9T7isiDBlVHc++tk59OgYxd2zV3H/uxkcLilvxIoDjy8BsALo61y1Ew5MAhZ4LyAiycCLeHb++V7t4cAHwJuqWt3fj3oe8L4EuNZpugWYX58NMcFrZK8O3HNhX95flcsHq3PcLsf4oKKyigfeW8OHGXk8eGl/7rnoxDt/b71io5l352juG9uXBWvyuGzmlyzdbiPHna46A8Dpp58OLAY2Au+paqaIPCoi453FZgDRwFwRyRCR6oC4HhgD3Oq0Z4hIkjPvl8ADIpKF55zAK/7bLBNs7rmwDyN6tOc3H6zn271FbpdjTqKisor73s1gwZo8fjluAHdf0OeUXt8iNIT7xvZj3p2jCQ8LYfJLS/nDwo2UVlQ2UMWBS5rTaEupqamanp7udhmmico7eJTLnvmS7h1aMe/OswgPs/scm5ryyirum5PBR+t28avLBvCT83rXa33FZRU89tFG3l62kwFdWjNzUhIDusT4qdrAISIrVTW1Zrv9hZiAEde2JU9cM4y1OYeYsXiT2+WYGsorq7h3zmo+WreLRy4fWO+dP0Cr8DAeu3oor96ayt7CMsY/9zUvfbHdLhf1kQWACSjjhnRhyqhuvPTlDj7fnF/3C0yjKKuo4p7Zq1m4bje/uWIgd4zp5df1XzigM4vvO5fz+8fy2MKN3PDyUnIPHvXrewQiCwATcH5zxSAGdGnNL+auIf+IXTPutrKKKqbPXsXHmbv57ZWDuP1c/+78q3WIjuDFm1J48tphrMs5xLiZX/Dh6lyaUzd3Y7MAMAEnsoXnURGFpRX8/D17VISbyiqquOvtVXyyYQ//M34wt53Ts0HfT0S4PjWRRfeOoX/n1tz3bgbT31nNweKyBn3f5soCwASkvp1b89srB/Pl1r3M+nK72+UEpdKKSu56eyWfbtzDo2mDueWsHo323t06tOLdn4zmwUv7s3j9bi6d+QVfbrUbSWuyADABa/KIRK4Y2pWnFm9m9U57tHBjKimv5Kd/XcWnG/P5/YQh3Dy6R6PXEBoi3H1BHz68+2xaR7bgpleW87sFmZSU2+Wi1SwATMASEf7wo6F0jonkZ3NW212jjaSkvJI7/7qSf23K5w9XD+WmUd1drWdIfBv+cc853HpWD17/z7dc+dxXrM+1Z0eBBYAJcG1atuDZyUnkHSzhNx+stxOCDaykvJJpb63k880FPP6jodwwspvbJQGe80K/Gz+YN28bwZGScq7+v695fkkWlUF+fsgCwAS8lO7tud95dMDclfaoiIZSUl7JHW+m8+XWAp68ZhiTRjSNnb+3Mf1iWXzfGC4Z1IUZizcz8cVvyN5fXPcLA5QFgAkKPz2/D6N7deC/52eyraDQ7XICztGySm5/I52vsvbyxDXDuP7MxLpf5JK2rcL58w3J/GnicDbvPsK4mV/wXnp2UB4dWgCYoBAaIvxpYhKRLUK4Z/Zqe26MHx0tq2TqGyv4etteZlw7nOtTm+7Ov5qIcHVyAh/fP4ahCW14aN5a7vzrSvYF2RCjFgAmaHRpE8lT1w1nw67DPL7IHhXhD8VlFdz2+gqWbt/H09cP59qUBLdLOiXxbVsy+/ZR/PryASzZVMClM79kyabguYPcAsAElYsGdubWs3rw2tff8tnGPW6X06wVl1Xw49dWsGzHPp6+Pomrk5vXzr9aSIgwbUxv5k8/m47R4fz49RU88sE6issCf4AhC+TfDOUAAArWSURBVAATdH51+QAGdY3hF3PX2PCCp6motIJbX1vBim/386eJSUxIbv4jug7sGsOHd5/NtDG9mL18J1c8+xUZ2QfdLqtBWQCYoBMRFspzNyRTUl7F/e9mBP2lgKeqsLSCW19bzsrvDvDMpGTSkpr/zr9aZItQfn35QGbfPorS8kqueeE/PP3PLZRXntJIts2GBYAJSr1jo/mftMF8s30fz3y2lbKKwPwD97cjJeXc8upyVu08yLOTkrlqeJzbJTWI0b07sOi+MaQNj+PZz7Zy9f99zZY9R9wuy+9sQBgTtFSVe+d4RqYKDw2hb+doBsfFMDiuDYPjYhjYNYaoiLC6VxQkqnf+a3MO8dzkZC4b2tXtkhrFx+t38esP1lNYWsGDl/TntnN6Ehoibpd1Sk40IIwFgAlqZRVVfLJhN+tyD7Eh7zCZeYfZX+R5cqQI9OwQxaC4GAZ5BUPH6AiXq258h52d/7qcQ/z5hmTGDQmOnX+1giOl/PqDdfxzwx5G9GjPU9cNp1uHVm6X5TMLAGN8oKrsPlxCZq4nDDLzDrFh12FyDnw/uEjnmIhjYVB9xJDQriUizetboa8OHS3n5leXsyHvEH++4QwuHdzF7ZJcoaq8vyqX3y3IpFKV31wxiMkjEpvFf/d6BYCIjAOeAUKBl1X18RrzHwBuByqAAuA2Vf3OmfcxMAr4SlWv9HrN68B5QPVTmW5V1YyT1WEBYNxyqLiczF3fHyVk5h0iK7+Q6vPHMZFhxx0lDI5rQ+/YKMJCm/dptkNHy7n5lWVs2HWY/7sxhYsHdXa7JNflHjzKQ/PW8HXWPs7vH8sT1wyjc0yk22Wd1GkHgIiEAluAi4EcYAUwWVU3eC1zAbBMVYtF5KfA+ao60Zl3EdAK+EktAfAPVZ3n60ZYAJimpKS8kk27j5CZd8gJhcNs2nWYUueEcnhYCAO6tGZwXAyDqs8rdImhZXioy5X75lBxOVNeWcbm3Ud4YcoZXDTQdv7VqqqUt5Z+x/9btJGIsFB+P2EI45vwCfETBYAvZ7hGAFmqut1Z0RwgDTgWAKq6xGv5pcAUr3mficj5p1m3MU1WZItQkhLbkpTY9lhbRWUV2/cWeULB6Ub6aO0u3lmeDUCIQK/Y6OO6jwbHxdC2Vbhbm1Grg8VlTHllGVt2F/KXm87gwgG28/cWEiLcclYPzu3bkZ/PXcPP3lnN4szd/D5tCO2jmtZ/y5PxJQDigWyv6Rxg5EmWnwos8vH9HxOR3wKfAQ+r6g8exCEi04BpAN26Nb2nCxrjLSw0hH6dW9Ovc2uuTva0qSo5B46yYZcnEDbkHWL5jv3Mz8g79rr4ti3p2TGK6IgwoiLCiIoIJSoizDMd7vW78xPtLFPd1sKPXU0Hisq48eVlZBUU8uLNKVzQv5Pf1h1oesVGM/cno3nxi+3M/HQLy7bv54lrhjaboyW/XuMmIlOAVDx9+3X5FbAbCAdmAb8EHq25kKrOcuaTmprafM5YG+MQERLbtyKxfavjTqDuKyw9FgqZeYfJOVBM/pESikorKSytoKi0ggofb1ILDws5FgpR4d+HRXVbq+PaQmsEyfdtVQq3v5HOtoJCXro5lfP6xTbUxxIwwkJDuPuCPlzQvxMPvJfB1DfSmZiayG+uHEjryBZul3dSvgRALuD9eL8Ep+04IjIWeAQ4r7Zv8jWp6i7n11IReQ34hQ+1GBMwOkRHcG7fWM7tW/tOVlUpraiiqLTi+1AoqzgWDkWlFRSWVnp+L6s4frnSCg4Wl5FzoJgiZ5nCsgp8uegvIiyEl29OZYzt/E/JoLgY5k8/m2c+3cpf/r2Nr7L28tR1wxndu4PbpZ2QLwGwAugrIj3x7PgnATd4LyAiycCLwDhV9elReiLSVVV3iecaqgnA+lOq3JgAJyJEtgglskUoHaLrvz5V5Wh5dUA4oXAsSL5vG9WrA0MT2tT/DYNQRFgoD40bwEUDO/Pz9zKY/NJSbju7Jw+N609ki6Z38t/Xy0AvB2biuQz0VVV9TEQeBdJVdYGIfAoMBaq/1e9U1fHOa78EBgDRwD5gqqouFpF/AbGAABnAnap60pE67CogY0xzUVxWweOLNvHmN9/ROzaKp69PYrjXBQONyW4EM8YYF3y1dS8PzltD/pFS7j6/N/dc1NevJ+19caIAaN53qRhjTBN3Tt+OfHzfGNKS4nj2X1lN6sFyFgDGGNPA2rRswdPXJ/HiTSnsOljClc99xawvtrn+KHILAGOMaSSXDu7C4vvHcEH/WP6wcBOTZy1l575i1+qxADDGmEbUMTqCv0xJ4enrh7Nx92HGPfMFby/7DjfOx1oAGGNMIxMRfnRGAovvG8MZ3drxyAfrufW1FY0+RKkFgDHGuCSubUvevG0Ej6YNZtmOfVw68wvmZ+Q22tGABYAxxrgoJES4eXQPFt07ht6xUdw7J4Pps1cfG5ioQd+7wd/BGGNMnXp2jGLunWfx0Lj+fLJhN5f86Qs+27inQd/TAsAYY5qI0BDhrvP7sGD6OXSMDmfqG+k8NG8NR0rKG+T9LACMMaaJGdg1hgXTz+HuC3ozb2UO42Z+2SA3j1kAGGNMExQeFsKDlw5g3k/PonenaOLatvT7e/h1PABjjDH+dUa3drx524gGWbcdARhjTJCyADDGmCBlAWCMMUHKAsAYY4KUBYAxxgQpCwBjjAlSFgDGGBOkLACMMSZINatB4UWkAPjuNF/eEdjrx3KaO/s8vmefxfHs8zheIHwe3VU1tmZjswqA+hCRdFVNdbuOpsI+j+/ZZ3E8+zyOF8ifh3UBGWNMkLIAMMaYIBVMATDL7QKaGPs8vmefxfHs8zhewH4eQXMOwBhjzPGC6QjAGGOMFwsAY4wJUkERACIyTkQ2i0iWiDzsdj1uEZFEEVkiIhtEJFNE7nW7pqZAREJFZLWI/MPtWtwmIm1FZJ6IbBKRjSIy2u2a3CIi9zt/J+tF5B0RiXS7Jn8L+AAQkVDgeeAyYBAwWUQGuVuVayqAn6vqIGAUcHcQfxbe7gU2ul1EE/EM8LGqDgCGE6Sfi4jEAz8DUlV1CBAKTHK3Kv8L+AAARgBZqrpdVcuAOUCayzW5QlV3qeoq5/cjeP64492tyl0ikgBcAbzsdi1uE5E2wBjgFQBVLVPVg+5W5aowoKWIhAGtgDyX6/G7YAiAeCDbazqHIN/pAYhIDyAZWOZuJa6bCTwEVLldSBPQEygAXnO6xF4WkSi3i3KDquYCTwE7gV3AIVX9xN2q/C8YAsDUICLRwN+A+1T1sNv1uEVErgTyVXWl27U0EWHAGcALqpoMFAFBec5MRNrh6SnoCcQBUSIyxd2q/C8YAiAXSPSaTnDagpKItMCz839bVd93ux6XnQ2MF5Fv8XQNXigif3W3JFflADmqWn1UOA9PIASjscAOVS1Q1XLgfeAsl2vyu2AIgBVAXxHpKSLheE7kLHC5JleIiODp392oqk+7XY/bVPVXqpqgqj3w/H/xL1UNuG95vlLV3UC2iPR3mi4CNrhYkpt2AqNEpJXzd3MRAXhCPMztAhqaqlaIyHRgMZ4z+a+qaqbLZbnlbOAmYJ2IZDhtv1bVhS7WZJqWe4C3nS9L24Efu1yPK1R1mYjMA1bhuXpuNQH4SAh7FIQxxgSpYOgCMsYYUwsLAGOMCVIWAMYYE6QsAIwxJkhZABhjTJCyADDGmCBlAWCMMUHq/wNm11WgKlo6UwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(epoch_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiKbPduz63zy"
      },
      "source": [
        "Expected 0.19 - 0.18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Bs1Fv7ko63zz"
      },
      "source": [
        "#### Hard training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "QZViyBL063zz"
      },
      "outputs": [],
      "source": [
        "batch_size=256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "GnrD0kq_63zz"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()\n",
        "\n",
        "optimizer_model = optim.AdamW(filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "                             lr=0.001, weight_decay=0.001)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer_model,\n",
        "                                                   max_lr=0.001,\n",
        "                                                   anneal_strategy='linear',\n",
        "                                                   epochs=10,\n",
        "                                                   steps_per_epoch=int(num_training_samples/batch_size),\n",
        "                                                   three_phase=True\n",
        "                                                   \n",
        "                                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852699df-a72b-4246-844b-43aa74086c1e",
        "tags": [],
        "id": "A0-D80XL63zz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Loss : 0.213080 - Learning Rate : 0.000367: 100%|| 16/16 [08:48<00:00, 33.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss 0.207385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Loss : 0.201565 - Learning Rate : 0.000694: 100%|| 16/16 [09:00<00:00, 33.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Loss 0.197888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Loss : 0.199880 - Learning Rate : 0.000980: 100%|| 16/16 [09:03<00:00, 33.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Loss 0.186947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Loss : 0.166767 - Learning Rate : 0.000673:  94%|| 15/16 [08:28<00:34, 34.23s/it]"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    # The dataset is reinitialized on each epoch so that new samples are generated on evry epoch\n",
        "    dataset = EmbeddingDataset(IMAGE_DIR, pd.concat([train, extra]).reset_index(drop=True), num_training_samples, transform=img_transform, easy_mode=False)\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=True, num_workers=1)\n",
        "    pbar = tqdm.tqdm(data_loader)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for sample in pbar:\n",
        "        img1, img2, y =  sample\n",
        "        optimizer_model.zero_grad() \n",
        "        with autocast():\n",
        "            op1, _ = model_conv(img1.to(device))\n",
        "            op2, _ = model_conv(img2.to(device))\n",
        "            loss = cosine_loss(op1, op2, y.to(device))\n",
        "            # loss = cross_entropy(op, sample['id'].to(device))\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_model)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "        running_loss += loss.item() * img1.size(0)\n",
        "        pbar.set_description('Epoch %d - Loss : %f - Learning Rate : %f' % (epoch+1, loss.item(), lr_scheduler.get_last_lr()[0]))\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print('Epoch %d - Loss %f' % (epoch+1, epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9hm4cl_63zz",
        "outputId": "42943b40-e3be-46d9-e7ad-961a45cdf27b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1847549252956274"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(epoch_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB42aGjH63zz"
      },
      "source": [
        "Expected 0.17 - 0.16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFhmK_AF63zz",
        "outputId": "ecd04cba-80ab-4120-bc91-91aa68780707"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f19a399e460>]"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(epoch_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH3sGod963z0",
        "outputId": "7aa9e31f-7b94-4f6f-c181-16307b3664fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Sequential(\n",
              "      (0): Linear(in_features=4096, out_features=128, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_conv.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtzbSOtr63z0"
      },
      "outputs": [],
      "source": [
        "cosine_similarity = nn.CosineSimilarity(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "660mKlSz63z0"
      },
      "outputs": [],
      "source": [
        "all_train_data = pd.concat([train, extra]).reset_index(drop=True)\n",
        "\n",
        "all_train_data = all_train_data.sort_values('turtle_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3JcyvZl63z0"
      },
      "outputs": [],
      "source": [
        "indexing_dataset = TurtleDataSet(IMAGE_DIR, all_train_data, turtle_ids, transform=img_transform, include_orientation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w20erIn63z0"
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(indexing_dataset, batch_size=512, shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCB1AfLX63z0",
        "outputId": "c4ff7aff-de78-4bde-a12e-445dee96aa8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|                                                                                                                                             | 5/26 [01:23<06:25, 18.37s/it]"
          ]
        }
      ],
      "source": [
        "ids = []\n",
        "emb_index = []\n",
        "with torch.no_grad():\n",
        "    for sample in tqdm.tqdm(data_loader):\n",
        "        emb = model_conv(sample['img'].to(device))\n",
        "        emb.to('cpu')\n",
        "        emb_index.append(emb)\n",
        "        ids.append(sample['id'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV3BXj8Q63z0"
      },
      "outputs": [],
      "source": [
        "emb_index = torch.cat(emb_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTjsr2nk63z1",
        "outputId": "c0d4d776-9da9-4f6c-bfa9-f5b036616239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12803, 64])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBxD84_563z1"
      },
      "outputs": [],
      "source": [
        "test['turtle_id'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_1GWyzR63z1"
      },
      "outputs": [],
      "source": [
        "test_dataset = TurtleDataSet(IMAGE_DIR, test, turtle_ids, transform=img_transform, include_orientation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCnzlnPI63z1"
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False, num_workers=1)\n",
        "\n",
        "# data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
        "\n",
        "test_image_ids = []\n",
        "pbar = tqdm.tqdm(data_loader)\n",
        "model_conv.eval()\n",
        "with torch.no_grad():\n",
        "    for sample in pbar:\n",
        "        test_image_ids.extend(sample['image_id'])\n",
        "        test_emb = model_conv(sample['img'].to(device))\n",
        "        # break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFSnipt_63z1",
        "outputId": "084481f8-b81b-4d7e-a03f-c1b0a6bf6ac6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "490"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_emb.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNxnwjgO63z1"
      },
      "outputs": [],
      "source": [
        "ids = torch.cat(ids)\n",
        "\n",
        "ids = ids.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoewGGMo63z2"
      },
      "outputs": [],
      "source": [
        "\n",
        "preds = []\n",
        "for idx in range(test_emb.shape[0]):\n",
        "    pred = cosine_similarity(emb_index, test_emb[idx]).topk(k=5).indices.cpu().numpy()\n",
        "    pred = list(map(lambda x: ids[x], pred))\n",
        "    preds.append(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "IgWbeq3E63z2"
      },
      "outputs": [],
      "source": [
        "preds = np.array(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWJjFJ1u63z2",
        "outputId": "c5a44604-559f-4d78-e774-234f5283a7b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(490, 5)"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS_zr9nO63z2"
      },
      "outputs": [],
      "source": [
        "preds = mapper(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fE3cA0v63z2",
        "outputId": "ada54787-9a9e-4159-f365-eddc0c7d7656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['new_turtle', 'new_turtle', 't_id_uJXT7dGu', 't_id_Ts5LyVQz',\n",
              "       't_id_AOWArhGb'], dtype='<U13')"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbGpZFPn63z2",
        "outputId": "3ca21463-a3e8-4631-e655-776880b41635"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "490"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_image_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaVrC-Z_63z2"
      },
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame({'image_id': test_image_ids,\n",
        "                               'prediction1': preds[:, 0],\n",
        "                               'prediction2': preds[:, 1],\n",
        "                               'prediction3': preds[:, 2],\n",
        "                               'prediction4': preds[:, 3],\n",
        "                               'prediction5': preds[:, 4]})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S5q3iT-cjgxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91Sm6Vf863z3",
        "outputId": "768e3ca4-ea75-4ae5-fb8a-a278c649994a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>prediction1</th>\n",
              "      <th>prediction2</th>\n",
              "      <th>prediction3</th>\n",
              "      <th>prediction4</th>\n",
              "      <th>prediction5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_6NEDKOYZ</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_uJXT7dGu</td>\n",
              "      <td>t_id_Ts5LyVQz</td>\n",
              "      <td>t_id_AOWArhGb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_57QZ4S9N</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_0g31STvR</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_OCGGJS5X</td>\n",
              "      <td>t_id_0g31STvR</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_uIlC9Gfo</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_D0gA44av</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_R2993S3S</td>\n",
              "      <td>t_id_D0gA44av</td>\n",
              "      <td>t_id_AOWArhGb</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_ksTLswDT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_2E011NB0</td>\n",
              "      <td>t_id_G5eoqwD8</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_ROFhVsy2</td>\n",
              "      <td>t_id_fjHGjp1w</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>ID_0RVNUKK1</td>\n",
              "      <td>t_id_AOWArhGb</td>\n",
              "      <td>t_id_G5eoqwD8</td>\n",
              "      <td>t_id_4ZfTUmwL</td>\n",
              "      <td>t_id_tjWepji1</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>ID_6405IKG3</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>ID_6WVPVB7S</td>\n",
              "      <td>t_id_ip3jsrYo</td>\n",
              "      <td>t_id_ZfvZBX4Q</td>\n",
              "      <td>t_id_g9Fz8PH7</td>\n",
              "      <td>t_id_MwnEYfqe</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>ID_47C5LL2G</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_dVQ4x3wz</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>ID_HZP6EJAK</td>\n",
              "      <td>t_id_JI6ba2Yx</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_uJXT7dGu</td>\n",
              "      <td>t_id_JI6ba2Yx</td>\n",
              "      <td>new_turtle</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>490 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_id    prediction1    prediction2    prediction3    prediction4  \\\n",
              "0    ID_6NEDKOYZ     new_turtle     new_turtle  t_id_uJXT7dGu  t_id_Ts5LyVQz   \n",
              "1    ID_57QZ4S9N     new_turtle     new_turtle     new_turtle  t_id_0g31STvR   \n",
              "2    ID_OCGGJS5X  t_id_0g31STvR     new_turtle  t_id_uIlC9Gfo     new_turtle   \n",
              "3    ID_R2993S3S  t_id_D0gA44av  t_id_AOWArhGb     new_turtle     new_turtle   \n",
              "4    ID_2E011NB0  t_id_G5eoqwD8     new_turtle  t_id_ROFhVsy2  t_id_fjHGjp1w   \n",
              "..           ...            ...            ...            ...            ...   \n",
              "485  ID_0RVNUKK1  t_id_AOWArhGb  t_id_G5eoqwD8  t_id_4ZfTUmwL  t_id_tjWepji1   \n",
              "486  ID_6405IKG3     new_turtle     new_turtle     new_turtle     new_turtle   \n",
              "487  ID_6WVPVB7S  t_id_ip3jsrYo  t_id_ZfvZBX4Q  t_id_g9Fz8PH7  t_id_MwnEYfqe   \n",
              "488  ID_47C5LL2G     new_turtle  t_id_dVQ4x3wz     new_turtle     new_turtle   \n",
              "489  ID_HZP6EJAK  t_id_JI6ba2Yx     new_turtle  t_id_uJXT7dGu  t_id_JI6ba2Yx   \n",
              "\n",
              "       prediction5  \n",
              "0    t_id_AOWArhGb  \n",
              "1       new_turtle  \n",
              "2    t_id_D0gA44av  \n",
              "3    t_id_ksTLswDT  \n",
              "4       new_turtle  \n",
              "..             ...  \n",
              "485     new_turtle  \n",
              "486     new_turtle  \n",
              "487     new_turtle  \n",
              "488     new_turtle  \n",
              "489     new_turtle  \n",
              "\n",
              "[490 rows x 6 columns]"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_PU0x6u63z3"
      },
      "outputs": [],
      "source": [
        "predictions_df.to_csv(os.path.join('predictions', dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M.csv\")),\n",
        "                      index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6HcqD-L63z3",
        "outputId": "4b0e3119-b86d-44ab-8777-e419f9e7c855"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_emb[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaYK-bIY63z3",
        "outputId": "d9d0736b-7c50-4cd8-92e3-bb8dd55966a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['img', 'image_id', 'id'])"
            ]
          },
          "execution_count": 216,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNAEcj6C63z3",
        "outputId": "07cc2ce4-1dbf-4056-f27d-be362b672595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([42,  8, 91, 38, 34, 16, 23,  0, 17, 12, 37, 67, 69, 45, 50, 56, 19,  4,\n",
              "        33, 92, 23, 60, 73, 47, 79, 65, 81, 89, 13,  6, 97, 48, 50, 54, 54, 55,\n",
              "        81, 93, 20, 15, 36, 23, 91, 44,  5, 23, 44, 78, 96, 30, 81, 38, 89, 54,\n",
              "         8, 35, 81, 56, 84, 94, 44, 20, 83,  7, 22, 75, 30, 47, 45, 13, 16, 45,\n",
              "        80, 54, 42,  8, 15, 29, 25, 87, 84, 54, 62,  3, 86,  3, 38, 23, 87, 85,\n",
              "        73, 47, 42, 47, 57, 64, 41, 47,  6, 33,  3, 54, 29, 15, 73, 54, 56,  0,\n",
              "        27, 78, 46, 60, 10, 54, 76, 56, 49, 42, 51, 48, 38, 63, 61, 45, 46, 56,\n",
              "         3, 23, 79, 84,  8, 88, 72, 82, 33, 94, 28, 89, 58, 48, 73, 72, 65, 67,\n",
              "        98, 67, 59, 40, 60, 43,  2, 90, 55, 13, 20, 84, 28, 65, 10, 63, 50, 81,\n",
              "        80, 14, 41, 76, 58, 97,  3, 26, 68, 70, 28, 66,  7, 28, 23, 75, 49, 36,\n",
              "        83, 56, 84, 35, 56, 84, 38,  9, 56,  9, 76, 66, 21, 33,  4, 63, 42, 66,\n",
              "        42, 94,  9, 85, 23, 36, 33,  5, 69,  2, 87, 35, 54, 44, 46, 98, 92, 33,\n",
              "         3, 33, 54, 37, 62, 37, 90, 32, 41, 46, 80, 23,  1, 91, 30, 77, 46, 33,\n",
              "        12, 47, 16, 77, 53, 30, 40, 81, 37, 56, 78, 23, 38, 95,  0, 96, 23,  6,\n",
              "        18, 36, 14, 87,  5, 83, 79, 45, 92, 28, 11, 92, 53, 81, 93, 41, 37, 77,\n",
              "         3, 36, 67, 84, 77, 51, 44, 55, 82, 28, 73, 87, 51, 79, 79, 77,  4, 22,\n",
              "        36, 45, 52, 59,  0, 12, 60, 71, 63, 33, 60, 45, 75, 33, 46, 35, 83, 15,\n",
              "         0, 50,  8, 45,  6, 21, 42, 31, 93, 45, 78, 54, 56, 12, 97, 23, 53, 15,\n",
              "        60, 43, 42, 23, 79, 47, 84,  1, 23, 47, 41, 14, 79, 39, 42, 17, 69, 34,\n",
              "        61, 86, 44, 96,  5,  7, 67, 67, 48, 56, 92, 88, 60, 47, 56, 40, 16, 95,\n",
              "        54, 99, 90, 16,  3,  9, 81, 82, 91, 81, 81, 36, 15, 79, 84, 13, 56, 88,\n",
              "        93, 73, 24, 86, 11, 14, 12, 94, 41, 54, 84, 12, 36, 17, 98, 57, 23, 33,\n",
              "        60, 42, 56, 15,  9, 98, 17, 78, 45, 15,  5,  6, 98, 24, 25, 67, 77, 58,\n",
              "        39, 56, 97, 36, 58, 18, 60, 33, 29, 76,  2,  4, 94,  7, 42, 20,  6, 35,\n",
              "        29, 92, 94, 59,  5, 76, 73, 42, 95, 16, 56, 31,  1, 52, 33,  8, 81,  0,\n",
              "        33,  8, 28, 50, 54, 79, 95, 35, 37,  5, 11, 85, 36, 81,  9, 54, 69, 73,\n",
              "         5, 32, 21, 33, 91, 60, 56,  5, 63, 44, 23,  6, 15, 46, 18, 23, 63, 42,\n",
              "        55, 12, 84, 45, 15, 86, 16, 67, 81, 33, 77, 56,  9, 15,  5, 78, 19, 29,\n",
              "        39, 20, 47,  5, 35, 95, 16,  3])"
            ]
          },
          "execution_count": 215,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(sample['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2D4m4di63z3"
      },
      "outputs": [],
      "source": [
        "sample.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mARuyJ7963z4",
        "outputId": "484fcf91-130e-4962-c94b-4fa4b36a57c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12803"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(indexing_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXi7OqMm63z4"
      },
      "source": [
        "### Triplet Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lot0At3bTfqE"
      },
      "outputs": [],
      "source": [
        "triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=nn.CosineSimilarity(), margin=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX7qyeFPVfnj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaQtb7RdVigm",
        "outputId": "a36a33d6-dbf2-40a5-bb6f-ba1d5adb67c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn6aJs0BbV-3"
      },
      "outputs": [],
      "source": [
        "dataset = TripletDataset(IMAGE_DIR, train, 32768, transform=img_transform, easy_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuFhXdP863z5"
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX-mKPR963z5"
      },
      "outputs": [],
      "source": [
        "optimizer_model = optim.SGD(\n",
        "            params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "            lr=0.0001,\n",
        "            momentum=0.0,\n",
        "            dampening=0,\n",
        "            nesterov=False\n",
        "        )\n",
        "\n",
        "# optimizer_model = optim.Adam(\n",
        "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "#             lr=0.001,\n",
        "#             betas=(0.9, 0.999),\n",
        "#             eps=1e-08,\n",
        "#             amsgrad=False,\n",
        "#             weight_decay=1e-5\n",
        "#         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNi9KT6EtRF9",
        "outputId": "0e34b6db-3887-49f4-cf3c-7ef4bbe778d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_CudaDeviceProperties(name='NVIDIA GeForce RTX 2060', major=7, minor=5, total_memory=6144MB, multi_processor_count=30)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.get_device_properties(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNq7jl2q63z5"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmuR1kiC63z5"
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
        "id": "Ieqj9oT463z6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Sequential(\n",
              "      (0): Linear(in_features=4096, out_features=101, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 386,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_conv.to(device)\n",
        "model_conv.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
        "id": "CQkXy_Wy63z6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss : 0.010000: 100%|| 4096/4096 [36:59<00:00,  1.85it/s]\n"
          ]
        }
      ],
      "source": [
        "pbar = tqdm.tqdm(data_loader)\n",
        "# with torch.set_grad_enabled(True):\n",
        "for triplet in pbar:\n",
        "    optimizer_model.zero_grad() \n",
        "    with autocast():\n",
        "        anc_embed = model_conv(triplet['anc_img'].to(device))\n",
        "        pos_embed = model_conv(triplet['pos_img'].to(device))\n",
        "        neg_embed = model_conv(triplet['neg_img'].to(device))\n",
        "        loss = triplet_loss(anc_embed, pos_embed, pos_embed)\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer_model)\n",
        "    scaler.update()\n",
        "    pbar.set_description('Loss : %f' % loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPFPGz3h63z6"
      },
      "outputs": [],
      "source": [
        "reserved_mem = torch.cuda.memory_reserved(0)\n",
        "allocated_mem = torch.cuda.memory_allocated(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1UzR9gq4FGE"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "predictions_from_scratch.to_csv('submission.csv')\n",
        "files.download('submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stxIzbz963z6"
      },
      "source": [
        "## Generate Result for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbzv7BpO63z6"
      },
      "outputs": [],
      "source": [
        "test['turtle_id'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23qYK2Ru63z6",
        "outputId": "5d9db57f-8d95-45b9-87cb-52d5e0d741e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=3, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=101, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model_conv.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wo-c3Gqw63z7"
      },
      "outputs": [],
      "source": [
        "test_dataset = TurtleDataSet(IMAGE_DIR, test, turtle_ids, transform=img_transform, include_orientation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDVjGcsk63z7",
        "outputId": "c064e454-4015-426f-eac8-d4d633eb4f53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "490"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xDE4zTHdjyKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anAH4NPw63z7",
        "outputId": "839c0a08-9089-4206-9a92-8926828ed176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 7/7 [00:30<00:00,  4.43s/it]\n"
          ]
        }
      ],
      "source": [
        "data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=70, shuffle=False, num_workers=1)\n",
        "\n",
        "# data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1)\n",
        "\n",
        "preds = []\n",
        "image_ids = []\n",
        "pbar = tqdm.tqdm(data_loader)\n",
        "model_conv.eval()\n",
        "with torch.no_grad():\n",
        "    for sample in pbar:\n",
        "        image_ids.extend(sample['image_id'])\n",
        "        test_emb = model_conv(sample['img'].to(device))\n",
        "        pred = test_emb.topk(5, dim=1).indices.cpu().numpy()\n",
        "        preds.append(pred)\n",
        "        # break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsfcIm4763z7"
      },
      "outputs": [],
      "source": [
        "image_ids = list(map(lambda x:x.upper(), image_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bninGHmD63z8"
      },
      "outputs": [],
      "source": [
        "preds = np.concatenate(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44rs6Y_O63z8",
        "outputId": "31499985-3347-478a-bc31-ec3cc2606ba7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([96, 39, 17, 15, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "sum(preds==100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kf64CpOD63z8",
        "outputId": "8db89610-d6da-420b-d107-40cb6841abf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([65, 31, 29, 24, 12])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(preds==100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI4tgTrV63z8"
      },
      "outputs": [],
      "source": [
        "preds = mapper(preds)\n",
        "\n",
        "predictions_df = pd.DataFrame({'image_id': image_ids,\n",
        "                               'prediction1': preds[:, 0],\n",
        "                               'prediction2': preds[:, 1],\n",
        "                               'prediction3': preds[:, 2],\n",
        "                               'prediction4': preds[:, 3],\n",
        "                               'prediction5': preds[:, 4]})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('predictions')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "9r2ISS6QlQpC",
        "outputId": "1aa0074b-024e-44cc-9083-1a29c5a41095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5bbb38716ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'predictions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nI0OWBt63z8"
      },
      "outputs": [],
      "source": [
        "predictions_df.to_csv(os.path.join('predictions', dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M.csv\")),\n",
        "                      index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOKzS57W63z8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCWqnYiQ63z9",
        "outputId": "13322780-d35b-4d7c-c076-a1948a4728fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2022-03-10-16-07.csv', '2022-03-10-18-39.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "os.listdir('predictions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RzziLPJ863z9",
        "outputId": "ddb15c60-bfe1-4749-84bb-ffd0ebb9dc1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b5445619-1406-40ea-87f7-115d40264acc\", \"2022-03-10-18-39.csv\", 39700)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "files.download('predictions/2022-03-10-18-39.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaWRCbCc63z9"
      },
      "outputs": [],
      "source": [
        "sample_submission = read_csv_from_web('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LZuE9s263z9",
        "outputId": "503d9647-6a41-43f3-b9f0-481bbeaf6e2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>prediction1</th>\n",
              "      <th>prediction2</th>\n",
              "      <th>prediction3</th>\n",
              "      <th>prediction4</th>\n",
              "      <th>prediction5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_6NEDKOYZ</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "      <td>t_id_qZ0iZYsC</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_57QZ4S9N</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "      <td>t_id_qZ0iZYsC</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_OCGGJS5X</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "      <td>t_id_qZ0iZYsC</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_R2993S3S</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "      <td>t_id_qZ0iZYsC</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_2E011NB0</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "      <td>t_id_qZ0iZYsC</td>\n",
              "      <td>new_turtle</td>\n",
              "      <td>t_id_d6aYXtor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      image_id prediction1    prediction2    prediction3 prediction4  \\\n",
              "0  ID_6NEDKOYZ  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
              "1  ID_57QZ4S9N  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
              "2  ID_OCGGJS5X  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
              "3  ID_R2993S3S  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
              "4  ID_2E011NB0  new_turtle  t_id_d6aYXtor  t_id_qZ0iZYsC  new_turtle   \n",
              "\n",
              "     prediction5  \n",
              "0  t_id_d6aYXtor  \n",
              "1  t_id_d6aYXtor  \n",
              "2  t_id_d6aYXtor  \n",
              "3  t_id_d6aYXtor  \n",
              "4  t_id_d6aYXtor  "
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qo69GwW63z9",
        "outputId": "35f5c300-2b1f-4beb-e49b-8ec805a09775"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8, 3, 128, 128])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample['img'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbWovopV63z9",
        "outputId": "e59b62e3-687b-43eb-979b-581039f54692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([26,  8, 76, 60, 66, 66, 55, 34])"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZPkk8Zi63z9",
        "outputId": "ea85349e-2251-4322-d630-c4ba0f9dbee4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.14583333333333331"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mapk(sample['id'], out.topk(5, dim=1).indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmaTQe5Q63z-"
      },
      "outputs": [],
      "source": [
        "mapk(out,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRXRDtflz2xP"
      },
      "outputs": [],
      "source": [
        "predictions = predictions_from_scratch[[\n",
        "    \"prediction1\", \"prediction2\", \"prediction3\", \"prediction4\", \"prediction5\"\n",
        "]]\n",
        "y_predict = predictions.values.tolist()\n",
        "\n",
        "# We don't actually know the true labels for the test set, so for the purposes\n",
        "# of demonstration we just assume that all of the images in the test set are of\n",
        "# a single turtle:\n",
        "assumed_y = [\"t_id_d6aYXtor\"] * len(y_predict)\n",
        "\n",
        "mapk_result = mapk(assumed_y, y_predict, k=5)\n",
        "print(\"With made up test set labels, our mapk with k=5 is\", mapk_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXDSxHvF63z-"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.cuda.amp import GradScaler, autocast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WNq652SB63z-"
      },
      "outputs": [],
      "source": [
        "class TurtleNet(nn.Module):\n",
        "    def __init__(self, num_classes, num_orientations, embedding_size):\n",
        "        super(TurtleNet, self).__init__()\n",
        "        \n",
        "        basenet = torchvision.models.alexnet(pretrained=True)\n",
        "        \n",
        "        self.features = basenet.features\n",
        "        # Freeze the conv weights of the pretrained model\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.adpool = nn.AdaptiveAvgPool2d(output_size=(6, 6))\n",
        "        self.dense_layers0 = basenet.classifier\n",
        "        self.dense_layers0[6] = nn.Linear(in_features=4096, out_features=128, bias=True)\n",
        "        \n",
        "        # self.dense_layers1 = nn.Sequential(nn.ReLU(), nn.Linear(in_features=1024, out_features=256, bias=True), nn.ReLU())\n",
        "        # self.dense_layers2 = nn.Sequential(nn.Linear(in_features=512, out_features=256, bias=True), nn.ReLU())\n",
        "        \n",
        "        self.embedding_head = nn.Sequential(nn.Linear(in_features=128, out_features=embedding_size, bias=True), nn.ReLU())\n",
        "        self.classification_head = nn.Sequential(nn.Linear(in_features=128, out_features=num_classes, bias=True), nn.ReLU())\n",
        "        self.orientation_head = nn.Sequential(nn.Linear(in_features=128, out_features=num_orientations, bias=True), nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.adpool(x)\n",
        "        x = self.dense_layers0(x)\n",
        "        x = self.dense_layers1(x)\n",
        "        \n",
        "        y_aux = self.orientation_head(x)\n",
        "        y_main = self.classification_head(x)\n",
        "        y_emb = self.embedding_head(x)\n",
        "        \n",
        "        \n",
        "        \n",
        "        return y_main, y_aux, y_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lA0a-di63z-"
      },
      "outputs": [],
      "source": [
        "model = TurtleNet(num_classes=len(turtle_ids)+1, # +1 for the new turtle class\n",
        "                  num_orientations=3, \n",
        "                  embedding_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC60HETU63z-"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(\n",
        "            params=filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=0.0001,\n",
        "            momentum=0.0,\n",
        "            dampening=0,\n",
        "            nesterov=False\n",
        "        )\n",
        "\n",
        "# optimizer_model = optim.Adam(\n",
        "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "#             lr=0.001,\n",
        "#             betas=(0.9, 0.999),\n",
        "#             eps=1e-08,\n",
        "#             amsgrad=False,\n",
        "#             weight_decay=1e-5\n",
        "#         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mSeXplp63z-"
      },
      "outputs": [],
      "source": [
        "img_transform = transforms.Compose([\n",
        "                                    SquarePad(),\n",
        "                                    transforms.PILToTensor(),\n",
        "                                    transforms.ConvertImageDtype(torch.float32),\n",
        "                                    transforms.Resize((128,128))\n",
        "                                                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQEmrZUe63z-"
      },
      "outputs": [],
      "source": [
        "dataset = TurtleDataSet(IMAGE_DIR, train_df, turtle_ids, transform=img_transform, include_orientation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKEDNxqD63z_"
      },
      "outputs": [],
      "source": [
        "cross_entropy = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
        "id": "GMXNEmY063z_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TurtleNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (dense_layers0): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=128, bias=True)\n",
              "  )\n",
              "  (embedding_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (classification_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=101, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (orientation_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=3, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhM_qcky63z_"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-JRTpmb63z_"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGaearIO63z_"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, \n",
        "                                                 base_lr=0.00001, \n",
        "                                                 max_lr=0.001, \n",
        "                                                 step_size_up=21, \n",
        "                                                 step_size_down=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "XqJ7xaxX63z_"
      },
      "outputs": [],
      "source": [
        "top_k_precisions = []\n",
        "epoch_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BypTsWoy63z_",
        "outputId": "1f44c064-12ad-4f2d-bb1c-5e09b44dac11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 73,  15,   8,  38,  48,  81,  72,  47,  75,  61,  56, 100,  65,  39,\n",
              "          4,  81])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvu2duz8630A",
        "outputId": "77fc1325-c12a-4feb-e212-50a6acf5729e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample['orientation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNHsdylp630A",
        "outputId": "dec9d769-cfae-43c8-b17e-af94e2dca851"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TurtleNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (adpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (dense_layers0): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=128, bias=True)\n",
              "  )\n",
              "  (embedding_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (classification_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=101, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (orientation_head): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=3, bias=True)\n",
              "    (1): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to('cpu')\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3nLQitK630A",
        "outputId": "6f6bf417-9891-4fd1-9b48-31d1f6ec9394"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (24576x6 and 9216x4096)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mTurtleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madpool(x)\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_layers0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_layers1(x)\n\u001b[1;32m     28\u001b[0m y_aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morientation_head(x)\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (24576x6 and 9216x4096)"
          ]
        }
      ],
      "source": [
        "model(sample['img'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
        "tags": [],
        "id": "QEBKYg9d630B"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                                                                                                      | 0/164 [00:00<?, ?it/s]/home/xion/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "  0%|                                                                                                                                                                                      | 0/164 [00:02<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ** On entry to GEMM_EX  parameter number 12 had an illegal value\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m---> 11\u001b[0m     op_main, op_aux, op_embed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     loss1 \u001b[38;5;241m=\u001b[39m cross_entropy(op, sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     13\u001b[0m     loss2 \u001b[38;5;241m=\u001b[39m cross_entropy(op, sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mTurtleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[0;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_layers0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_layers1(x)\n\u001b[1;32m     28\u001b[0m     y_aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morientation_head(x)\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/torchenv/lib/python3.8/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasGemmEx( handle, opa, opb, m, n, k, &falpha, a, CUDA_R_16F, lda, b, CUDA_R_16F, ldb, &fbeta, c, CUDA_R_16F, ldc, CUDA_R_32F, CUBLAS_GEMM_DFALT_TENSOR_OP)`"
          ]
        }
      ],
      "source": [
        "for epoch in range(25):\n",
        "    \n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, num_workers=1)\n",
        "    pbar = tqdm.tqdm(data_loader)\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for sample in pbar:\n",
        "        optimizer.zero_grad() \n",
        "        with autocast():\n",
        "            op_main, op_aux, op_embed = model(sample['img'].to(device))\n",
        "            loss1 = cross_entropy(op, sample['id'].to(device))\n",
        "            loss2 = cross_entropy(op, sample['orientation'].to(device))\n",
        "            loss = loss1+0.4*loss2\n",
        "            \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_model)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "        running_loss += loss1.item() * sample['img'].size(0)\n",
        "        top_k_precision = mapk(sample['id'], op_main.topk(5, dim=1).indices)\n",
        "        top_k_precisions.append(top_k_precision)\n",
        "        pbar.set_description('Epoch %d - MAP@k : %f - Learning Rate : %f' % (epoch+1, top_k_precision, lr_scheduler.get_last_lr()[0]))\n",
        "    epoch_loss = running_loss / len(dataset)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print('Epoch %d - MAP@k : %f - Loss %f' % (epoch+1, np.mean(top_k_precisions[-21:]), epoch_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2xnOd4Z630B"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVyLMsaa630B"
      },
      "source": [
        "### Custom Model\n",
        "Trained from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "-sc_Zcxx630B"
      },
      "outputs": [],
      "source": [
        "class TurtleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TurtleNet, self).__init__()\n",
        "        \n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(1,64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        \n",
        "        self.feature_classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=False),\n",
        "            nn.Linear(in_features=32768, out_features=4096, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5, inplace=False),\n",
        "            nn.Linear(in_features=4096, out_features=512, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5, inplace=False),\n",
        "            nn.Linear(in_features=512, out_features=100, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        x = self.feature_classifier(x)\n",
        "        return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEf1AaiB630C"
      },
      "outputs": [],
      "source": [
        "model_conv = TurtleNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJovJSOk630C"
      },
      "outputs": [],
      "source": [
        "img_transform = transforms.Compose([\n",
        "                                    transforms.Grayscale(num_output_channels=1),\n",
        "                                    SquarePad(),\n",
        "                                    transforms.PILToTensor(),\n",
        "                                    transforms.ConvertImageDtype(torch.float32),\n",
        "                                    transforms.Resize((128,128))\n",
        "                                                      ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZsu28-u630C"
      },
      "outputs": [],
      "source": [
        "# Clear out anymemory if possible\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
        "id": "V1Kgrc97630C"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Sequential(\n",
              "      (0): Linear(in_features=4096, out_features=101, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 382,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_conv.to(device)\n",
        "model_conv.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hoPmBym630D"
      },
      "outputs": [],
      "source": [
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RewMoOq630D"
      },
      "outputs": [],
      "source": [
        "dataset = TurtleDataSet(IMAGE_DIR, train, transform=img_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HKNmPqN630D"
      },
      "outputs": [],
      "source": [
        "optimizer_model = optim.SGD(\n",
        "            params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "            lr=0.0001,\n",
        "            momentum=0.0,\n",
        "            dampening=0,\n",
        "            nesterov=False\n",
        "        )\n",
        "\n",
        "# optimizer_model = optim.Adam(\n",
        "#             params=filter(lambda p: p.requires_grad, model_conv.parameters()),\n",
        "#             lr=0.001,\n",
        "#             betas=(0.9, 0.999),\n",
        "#             eps=1e-08,\n",
        "#             amsgrad=False,\n",
        "#             weight_decay=1e-5\n",
        "#         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f84986-1a75-4239-a6a1-80f1fa0d99b0",
        "tags": [],
        "id": "tw-o8Z1-630D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss : 4.601562: 100%|| 269/269 [01:31<00:00,  2.95it/s]\n",
            "Epoch 2 - Loss : 4.585938: 100%|| 269/269 [00:43<00:00,  6.23it/s]\n",
            "Epoch 3 - Loss : 4.609375: 100%|| 269/269 [00:43<00:00,  6.14it/s]\n",
            "Epoch 4 - Loss : 4.570312: 100%|| 269/269 [00:49<00:00,  5.47it/s]\n",
            "Epoch 5 - Loss : 4.585938: 100%|| 269/269 [00:47<00:00,  5.71it/s]\n",
            "Epoch 6 - Loss : 4.636719: 100%|| 269/269 [00:49<00:00,  5.42it/s]\n",
            "Epoch 7 - Loss : 4.570312: 100%|| 269/269 [00:49<00:00,  5.45it/s]\n",
            "Epoch 8 - Loss : 4.613281: 100%|| 269/269 [00:48<00:00,  5.55it/s]\n",
            "Epoch 9 - Loss : 4.617188: 100%|| 269/269 [00:48<00:00,  5.54it/s]\n",
            "Epoch 10 - Loss : 4.625000: 100%|| 269/269 [00:48<00:00,  5.51it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# with torch.set_grad_enabled(True):\n",
        "for epoch in range(10):\n",
        "    \n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=1)\n",
        "    pbar = tqdm.tqdm(data_loader)\n",
        "    for sample in pbar:\n",
        "        # break\n",
        "        optimizer_model.zero_grad() \n",
        "        with autocast():\n",
        "            op = model_conv(sample['img'].to(device))\n",
        "            loss = cross_entropy(op, sample['id'].to(device))\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer_model)\n",
        "        scaler.update()\n",
        "        pbar.set_description('Epoch %d - Loss : %f' % (epoch+1, loss.item()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Turtle_Recall_InceptionNet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b3c1ff6fd74aa8841c0d497fa62f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7a76b3b959040329297dc86ccc7a2f5",
              "IPY_MODEL_118596bb302d4ff29aca97565198bdd7",
              "IPY_MODEL_69b0cee3ee7347c0a17932e70ac739bc"
            ],
            "layout": "IPY_MODEL_7676578519494d28940a7538d39bfa87"
          }
        },
        "c7a76b3b959040329297dc86ccc7a2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2a46034480b4df4a9d9e37c63f4c999",
            "placeholder": "",
            "style": "IPY_MODEL_4f7bcfb271294b529e03d201f92b98e9",
            "value": "100%"
          }
        },
        "118596bb302d4ff29aca97565198bdd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbbeeb6fd1c42308809d9f5fff5adbf",
            "max": 108949747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62d0f34df8b844e3897d66a8ed36d401",
            "value": 108949747
          }
        },
        "69b0cee3ee7347c0a17932e70ac739bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b0e6276294402a9f4a9dd48ca1bfa0",
            "placeholder": "",
            "style": "IPY_MODEL_e44a3a6d809d41dfbee8dc5cc53db6e2",
            "value": " 104M/104M [00:01&lt;00:00, 62.8MB/s]"
          }
        },
        "7676578519494d28940a7538d39bfa87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a46034480b4df4a9d9e37c63f4c999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7bcfb271294b529e03d201f92b98e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dbbeeb6fd1c42308809d9f5fff5adbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d0f34df8b844e3897d66a8ed36d401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65b0e6276294402a9f4a9dd48ca1bfa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e44a3a6d809d41dfbee8dc5cc53db6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}